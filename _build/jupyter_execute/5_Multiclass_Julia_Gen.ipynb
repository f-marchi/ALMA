{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Passionate Child's Introduction to Gen"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "hide-input",
     "hide-output"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110-element PooledArrays.PooledVector{String, UInt32, Vector{UInt32}}:\n",
       " \"AML with t(9;11)(p22;q23.3)/KMT2A-rearrangement\"\n",
       " \"AML with t(9;11)(p22;q23.3)/KMT2A-rearrangement\"\n",
       " \"AML with inv(16)(p13.1q22) or t(16;16)(p13.1;q22)/CBFB::MYH11\"\n",
       " \"AML with t(9;11)(p22;q23.3)/KMT2A-rearrangement\"\n",
       " \"AML with inv(16)(p13.1q22) or t(16;16)(p13.1;q22)/CBFB::MYH11\"\n",
       " \"AML with t(9;11)(p22;q23.3)/KMT2A-rearrangement\"\n",
       " \"AML with t(8;21)(q22;q22.1)/RUNX1::RUNX1T1\"\n",
       " \"AML with t(8;21)(q22;q22.1)/RUNX1::RUNX1T1\"\n",
       " \"AML with t(8;21)(q22;q22.1)/RUNX1::RUNX1T1\"\n",
       " \"AML with t(9;11)(p22;q23.3)/KMT2A-rearrangement\"\n",
       " \"AML with inv(16)(p13.1q22) or t(16;16)(p13.1;q22)/CBFB::MYH11\"\n",
       " \"AML with other rare recurring translocations\"\n",
       " \"AML with t(8;21)(q22;q22.1)/RUNX1::RUNX1T1\"\n",
       " â‹®\n",
       " \"AML with inv(16)(p13.1q22) or t(16;16)(p13.1;q22)/CBFB::MYH11\"\n",
       " \"AML with t(9;11)(p22;q23.3)/KMT2A-rearrangement\"\n",
       " \"AML with t(8;21)(q22;q22.1)/RUNX1::RUNX1T1\"\n",
       " \"AML with t(9;11)(p22;q23.3)/KMT2A-rearrangement\"\n",
       " \"AML with t(8;21)(q22;q22.1)/RUNX1::RUNX1T1\"\n",
       " \"AML with t(8;21)(q22;q22.1)/RUNX1::RUNX1T1\"\n",
       " \"AML with inv(16)(p13.1q22) or t(16;16)(p13.1;q22)/CBFB::MYH11\"\n",
       " \"AML with t(6;9)(p23;q34.1)/DEK::NUP214\"\n",
       " \"AML with t(9;11)(p22;q23.3)/KMT2A-rearrangement\"\n",
       " \"AML with t(8;21)(q22;q22.1)/RUNX1::RUNX1T1\"\n",
       " \"AML with t(8;21)(q22;q22.1)/RUNX1::RUNX1T1\"\n",
       " \"AML with t(8;21)(q22;q22.1)/RUNX1::RUNX1T1\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using DataFrames, CSV\n",
    "\n",
    "input_path = \"../Data/Intermediate_Files/\"\n",
    "output_path = \"../Data/Processed_Data/\"\n",
    "\n",
    "# Load pacmap output data\n",
    "df = CSV.read(output_path*\"pacmap_output/pacmap_5d_output_acute_leukemia_cleaned.csv\", DataFrame)\n",
    "\n",
    "# Define X and y\n",
    "X = Matrix(df[:, [\"PaCMAP 1\", \"PaCMAP 2\", \"PaCMAP 3\", \"PaCMAP 4\", \"PaCMAP 5\"]])  # shape (n_samples=1399, n_features=5)\n",
    "y = df[:, \"ELN AML 2022 Diagnosis\"]  # shape (n_samples=1399,) with 11 string classes\n",
    "\n",
    "X_train = X[df[!, \"Train Test\"] .== \"Discovery (train) Samples\", :]\n",
    "y_train = y[df[!, \"Train Test\"] .== \"Discovery (train) Samples\"]\n",
    "X_test = X[df[!, \"Train Test\"] .== \"Validation (test) Samples\", :]\n",
    "y_test = y[df[!, \"Train Test\"] .== \"Validation (test) Samples\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "hide-input",
     "hide-output"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DynamicDSLFunction{Any}(Dict{Symbol, Any}(), Dict{Symbol, Any}(), Type[Array{Float64}, Int64], false, Union{Nothing, Some{Any}}[nothing, nothing], var\"##classifier_model#297\", Bool[0, 0], false)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Gen\n",
    "using LinearAlgebra\n",
    "\n",
    "@gen function classifier_model(features::Array{Float64}, num_classes::Int)\n",
    "    # Define prior over weights and bias\n",
    "    weights = @trace(mvnormal(zeros(num_classes, size(features, 2)), I(num_classes)), :weights)\n",
    "    bias = @trace(normal(0, 1), :bias)\n",
    "    \n",
    "    # Compute the logits\n",
    "    logits = weights * features' .+ bias\n",
    "    \n",
    "    # Define likelihood\n",
    "    @trace(categorical_softmax(logits), :class)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = length(unique(y_train))  # Assuming y_train is your vector of class labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "MethodError: no method matching random(::Gen.MultivariateNormal, ::Matrix{Float64}, ::Diagonal{Bool, Vector{Bool}})\n\n\u001b[0mClosest candidates are:\n\u001b[0m  random(\u001b[91m::Gen.TransformedDistribution{T, U}\u001b[39m, ::Any...) where {T, U}\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[35mGen\u001b[39m \u001b[90m~/.julia/packages/Gen/Dne3u/src/modeling_library/dist_dsl/\u001b[39m\u001b[90m\u001b[4mtransformed_distribution.jl:19\u001b[24m\u001b[39m\n\u001b[0m  random(\u001b[91m::HeterogeneousMixture{T}\u001b[39m, ::Any, ::Any...) where T\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[35mGen\u001b[39m \u001b[90m~/.julia/packages/Gen/Dne3u/src/modeling_library/\u001b[39m\u001b[90m\u001b[4mmixture.jl:214\u001b[24m\u001b[39m\n\u001b[0m  random(\u001b[91m::HomogeneousMixture\u001b[39m, ::Any, ::Any...)\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[35mGen\u001b[39m \u001b[90m~/.julia/packages/Gen/Dne3u/src/modeling_library/\u001b[39m\u001b[90m\u001b[4mmixture.jl:72\u001b[24m\u001b[39m\n\u001b[0m  ...\n",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching random(::Gen.MultivariateNormal, ::Matrix{Float64}, ::Diagonal{Bool, Vector{Bool}})\n\n\u001b[0mClosest candidates are:\n\u001b[0m  random(\u001b[91m::Gen.TransformedDistribution{T, U}\u001b[39m, ::Any...) where {T, U}\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[35mGen\u001b[39m \u001b[90m~/.julia/packages/Gen/Dne3u/src/modeling_library/dist_dsl/\u001b[39m\u001b[90m\u001b[4mtransformed_distribution.jl:19\u001b[24m\u001b[39m\n\u001b[0m  random(\u001b[91m::HeterogeneousMixture{T}\u001b[39m, ::Any, ::Any...) where T\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[35mGen\u001b[39m \u001b[90m~/.julia/packages/Gen/Dne3u/src/modeling_library/\u001b[39m\u001b[90m\u001b[4mmixture.jl:214\u001b[24m\u001b[39m\n\u001b[0m  random(\u001b[91m::HomogeneousMixture\u001b[39m, ::Any, ::Any...)\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[35mGen\u001b[39m \u001b[90m~/.julia/packages/Gen/Dne3u/src/modeling_library/\u001b[39m\u001b[90m\u001b[4mmixture.jl:72\u001b[24m\u001b[39m\n\u001b[0m  ...\n",
      "",
      "Stacktrace:",
      " [1] traceat(state::Gen.GFSimulateState, dist::Gen.MultivariateNormal, args::Tuple{Matrix{Float64}, Diagonal{Bool, Vector{Bool}}}, key::Symbol)",
      "   @ Gen ~/.julia/packages/Gen/Dne3u/src/dynamic/simulate.jl:19",
      " [2] var\"##classifier_model#297\"(state#294::Gen.GFSimulateState, features::Matrix{Float64}, num_classes::Int64)",
      "   @ Main ./In[9]:6",
      " [3] exec(gen_fn::DynamicDSLFunction{Any}, state::Gen.GFSimulateState, args::Tuple{Matrix{Float64}, Int64})",
      "   @ Gen ~/.julia/packages/Gen/Dne3u/src/dynamic/dynamic.jl:58",
      " [4] simulate(gen_fn::DynamicDSLFunction{Any}, args::Tuple{Matrix{Float64}, Int64})",
      "   @ Gen ~/.julia/packages/Gen/Dne3u/src/dynamic/simulate.jl:61",
      " [5] top-level scope",
      "   @ In[11]:9"
     ]
    }
   ],
   "source": [
    "# Define a proposal distribution\n",
    "@gen function proposal_distribution(prev_trace)\n",
    "    # Sample new parameters around the previous parameters\n",
    "    weights = @trace(mvnormal(get_retval(prev_trace[:weights]), 0.1), :weights)\n",
    "    bias = @trace(normal(get_retval(prev_trace[:bias]), 0.1), :bias)\n",
    "end\n",
    "\n",
    "# Initialize the trace\n",
    "initial_trace = Gen.simulate(classifier_model, (X_train, num_classes))\n",
    "traces = [initial_trace]\n",
    "\n",
    "# Perform inference\n",
    "for i in 1:1000\n",
    "    # Propose a new trace\n",
    "    proposal_trace = Gen.simulate(proposal_distribution, (traces[end],))\n",
    "    \n",
    "    # Compute acceptance probability\n",
    "    acc_prob = Gen.get_score(proposal_trace) - Gen.get_score(traces[end])\n",
    "    \n",
    "    # Accept or reject\n",
    "    if rand() < exp(acc_prob)\n",
    "        push!(traces, proposal_trace)\n",
    "    end\n",
    "end\n",
    "\n",
    "# Make predictions for test data\n",
    "predictions = []\n",
    "for trace in traces\n",
    "    weights = get_retval(trace[:weights])\n",
    "    bias = get_retval(trace[:bias])\n",
    "    logits = weights * X_test' .+ bias\n",
    "    push!(predictions, argmax(logits, dims=1))\n",
    "end\n",
    "\n",
    "# Compute accuracy\n",
    "accuracy = mean([predictions[i] == y_test[i] for i in 1:length(y_test)])\n",
    "\n",
    "println(\"Accuracy: \", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SPPL alternative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __SPPL__: Sum-Product Probabilistic Language\n",
    "\n",
    "- __Github__: [https://github.com/probsys/sppl](https://github.com/probsys/sppl)\n",
    "\n",
    "- __Paper__: [SPPL: Probabilistic Programming with Fast Exact Symbolic Inference](https://arxiv.org/abs/2010.03485)\n",
    "\n",
    "- __Intro on SPNs__: [Visualizing and understanding Sum-Product Networks](https://link.springer.com/article/10.1007/s10994-018-5760-y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.2",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}