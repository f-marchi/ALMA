{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimension Reduction with PaCMAP"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where the data at?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = '../Data/Processed_Data/'\n",
    "output_path = '../Data/Processed_Data/PaCMAP_Results/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../Data/Processed_Data/x.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_pickle\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_path\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mx.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m y \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(input_path\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Dataset (df) contains \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m rows (mC sites) and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m columns (samples).\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/projects/MethylScore/Code/.venv_py38/lib/python3.8/site-packages/pandas/io/pickle.py:179\u001b[0m, in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;124;03mLoad pickled pandas object (or any object) from file.\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;124;03m4    4    9\u001b[39;00m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    178\u001b[0m excs_to_catch \u001b[38;5;241m=\u001b[39m (\u001b[38;5;167;01mAttributeError\u001b[39;00m, \u001b[38;5;167;01mImportError\u001b[39;00m, \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m)\n\u001b[0;32m--> 179\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;66;03m# 1) try standard library Pickle\u001b[39;00m\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;66;03m# 2) try pickle_compat (older pandas version) to handle subclass changes\u001b[39;00m\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;66;03m# 3) try pickle_compat with latin-1 encoding upon a UnicodeDecodeError\u001b[39;00m\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    191\u001b[0m         \u001b[38;5;66;03m# TypeError for Cython complaints about object.__new__ vs Tick.__new__\u001b[39;00m\n\u001b[1;32m    192\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/projects/MethylScore/Code/.venv_py38/lib/python3.8/site-packages/pandas/io/common.py:868\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    860\u001b[0m             handle,\n\u001b[1;32m    861\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    864\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    865\u001b[0m         )\n\u001b[1;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    869\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[1;32m    871\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../Data/Processed_Data/x.pkl'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "x = pd.read_pickle(input_path+'x.pkl')\n",
    "y = pd.read_csv(input_path+'y.csv', index_col=0)\n",
    "\n",
    "print(\n",
    "    f' Dataset (df) contains {x.shape[1]} rows (mC sites) and {x.shape[0]} columns (samples).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load control and relapse data\n",
    "ctrl_rel = pd.read_pickle(input_path+'control_relapse.pkl')\n",
    "\n",
    "# Split control and relapse data into x and y\n",
    "ctrl_rel_x = ctrl_rel[x.columns]\n",
    "ctrl_rel_y = ctrl_rel[y.columns]\n",
    "\n",
    "# Split control and relapse data into control and relapse\n",
    "ctrl_y = ctrl_rel_y[ctrl_rel_y['Sample Type'].isin(['Bone Marrow Normal','Blood Derived Normal'])]\n",
    "rel_y = ctrl_rel_y[~ctrl_rel_y['Sample Type'].isin(['Bone Marrow Normal','Blood Derived Normal'])]\n",
    "\n",
    "# Apply to x\n",
    "ctrl_x = ctrl_rel_x.T[ctrl_y.index].T\n",
    "rel_x = ctrl_rel_x.T[rel_y.index].T"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will split the data into a training/discovery and testing/validation set.\n",
    "\n",
    "We will use ```y_train``` to denote the training set, and ```y_test``` to denote the testing set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discovery dataset (train) contains 310545 rows (mC sites) and 1553 columns (samples)\n",
      "\n",
      "AAML1031    704\n",
      "AAML0531    630\n",
      "AAML03P1     72\n",
      "AML05        64\n",
      "CCG2961      42\n",
      "NaN          41\n",
      "\n",
      "Validation dataset (test) contains 310545 rows (mC sites) and 209 columns (samples).\n",
      "\n",
      "AML02    167\n",
      "AML08     42\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split train and test by clinical trial\n",
    "y_train = y[~y['Clinical Trial'].isin(['AML02', 'AML08'])]\n",
    "# y_train = y_train[y_train['Sample Type'].isin(['Diagnosis',\n",
    "#        'Primary Blood Derived Cancer - Bone Marrow', 'Bone Marrow Normal',\n",
    "#        'Primary Blood Derived Cancer - Peripheral Blood',\n",
    "#        'Blood Derived Normal'])]\n",
    "\n",
    "y_test = y[y['Clinical Trial'].isin(['AML02', 'AML08'])]\n",
    "\n",
    "# Select samples in x that are in y_train\n",
    "x_train = x.loc[y_train.index]\n",
    "x_test = x.loc[y_test.index]\n",
    "\n",
    "# x_train = pd.concat([x_train, ctrl_x], axis=0)\n",
    "# y_train = pd.concat([y_train, ctrl_y], axis=0,keys=['Diagnosis','Control'], names=['sample_type'])\n",
    "\n",
    "\n",
    "print(\n",
    "    f\"Discovery dataset (train) contains {x_train.shape[1]} rows (mC sites) and {x_train.shape[0]} columns (samples)\")\n",
    "print(\n",
    "    f\"\\n{y_train['Clinical Trial'].value_counts(dropna=False).to_string()}\\n\")\n",
    "print(\n",
    "    f\"Validation dataset (test) contains {x_test.shape[1]} rows (mC sites) and {x_test.shape[0]} columns (samples).\")\n",
    "print(f\"\\n{y_test['Clinical Trial'].value_counts(dropna=False).to_string()}\\n\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Correction with pyCombat"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __pyCombat__: a Python tool for batch effects correction in high-throughput molecular data using empirical Bayes methods\n",
    "\n",
    "- __Github__: [https://epigenelabs.github.io/pyComBat/](https://epigenelabs.github.io/pyComBat/)\n",
    "\n",
    "- __Implementation Paper__: [bioRxiv](https://doi.org/10.1101/2020.03.17.995431)\n",
    "\n",
    "- __Original Paper__: [Biostatistics](https://pubmed.ncbi.nlm.nih.gov/16632515/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 batches.\n",
      "Adjusting for 0 covariate(s) or covariate level(s).\n",
      "Standardizing Data across genes.\n",
      "Fitting L/S model and finding priors.\n",
      "Finding parametric adjustments.\n",
      "Adjusting the Data\n",
      "Succesfully corrected batch effects in the training dataset.\n"
     ]
    }
   ],
   "source": [
    "from combat.pycombat import pycombat\n",
    "\n",
    "# Correct batch effects in the training dataset\n",
    "x_train2 = pycombat(x_train.T, y_train['Batch']).T\n",
    "\n",
    "print('Succesfully corrected batch effects in the training dataset.')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimension Reduction with PaCMAP"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __PaCMAP__: Large-scale Dimension Reduction Technique Preserving Both Global and Local Structure\n",
    "\n",
    "- __Github__: [https://github.com/YingfanWang/PaCMAP](https://github.com/YingfanWang/PaCMAP)\n",
    "\n",
    "- __Paper__: [Journal of Machine Learning Research](https://jmlr.org/papers/v22/20-1061.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": [
     "hide-input",
     "remove-output"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\flourenco\\Desktop\\Projects\\Methylation_Project_v2\\Code\\.venv_pacmap\\lib\\site-packages\\pacmap\\pacmap.py:819: UserWarning: Warning: random state is set to 42\n",
      "  warnings.warn(f'Warning: random state is set to {_RANDOM_STATE}')\n"
     ]
    }
   ],
   "source": [
    "import pacmap\n",
    "\n",
    "\n",
    "def run_pacmap(x_train, x_test, n_components=2):\n",
    "    \"\"\"\n",
    "    Run PaCMAP on the training dataset apply learned parameters to the train and test.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x_train : pandas.DataFrame\n",
    "        Training dataset.\n",
    "    x_test : pandas.DataFrame\n",
    "        Test dataset.\n",
    "    n_components : int, optional\n",
    "        Number of components. The default is 2.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    embedding : numpy.ndarray\n",
    "        Embedding of the training dataset.\n",
    "    embedding_test : numpy.ndarray\n",
    "        Embedding of the test dataset.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize PaCMAP. Note: hyperparameter tuning has been performed.\n",
    "    reducer = pacmap.PaCMAP(n_components=n_components, n_neighbors=15,\n",
    "                            MN_ratio=0.4, FP_ratio=16.0, random_state=42,\n",
    "                            lr=0.1, num_iters=5000)\n",
    "\n",
    "    # Fit (estimate) parameters to the training dataset to learn the embedding\n",
    "    embedding = reducer.fit_transform(x_train)\n",
    "\n",
    "    # Transform (apply) parameters to the test dataset\n",
    "    embedding_test = reducer.transform(x_test, basis=x_train.copy())\n",
    "\n",
    "    return embedding, embedding_test\n",
    "\n",
    "\n",
    "embedding, embedding_test = run_pacmap(x_train2, x_test, n_components=3)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{note}\n",
    "\n",
    "You may have noticed that we called two methods in the PaCMAP class: ```fit``` and ```transform```.\n",
    "\n",
    "- ```fit``` means to learn the parameters of a model _from_ a dataset.\n",
    "\n",
    "- ```transform``` means to apply the learned parameters of a model _to_ a dataset.\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfuly saved 1553 x_train samples and 209 x_test samples.\n",
      "Path: ../Data/Processed_Data/PaCMAP_Results/\n"
     ]
    }
   ],
   "source": [
    "# Transform df to pandas dataframe format\n",
    "embedding = pd.DataFrame(embedding, index=x_train2.index,\n",
    "                         columns=['PaCMAP 1', 'PaCMAP 2', 'PaCMAP 3'])\n",
    "embedding_test = pd.DataFrame(embedding_test, index=x_test.index,\n",
    "                              columns=['PaCMAP 1', 'PaCMAP 2', 'PaCMAP 3'])\n",
    "\n",
    "# Save embeddings\n",
    "embedding.to_pickle(output_path+'embedding.pkl')\n",
    "embedding_test.to_pickle(output_path+'embedding_test.pkl')\n",
    "\n",
    "print(\n",
    "    f'Successfuly saved {embedding.shape[0]} x_train samples and {embedding_test.shape[0]} x_test samples.\\nPath: {output_path}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": [
     "remove-input",
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python implementation: CPython\n",
      "Python version       : 3.10.10\n",
      "IPython version      : 8.8.0\n",
      "\n",
      "numpy  : 1.23.5\n",
      "pandas : 1.5.2\n",
      "sklearn: 1.2.0\n",
      "combat : 0.3.3\n",
      "pacmap : 0.7.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# produce a list of the loaded modules\n",
    "%watermark -v -p numpy,pandas,sklearn,combat,pacmap"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_pacmap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "7a1d9c019193b28697b8b64517a1f3a4ad54dba083fd65d3a4f9842557772cb3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}