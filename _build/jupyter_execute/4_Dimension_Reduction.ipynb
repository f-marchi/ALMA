{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimension Reduction with PaCMAP"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where the data at?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = '../Data/Processed_Data/'\n",
    "output_path = '../Data/Processed_Data/PaCMAP_Results/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Dataset (df) contains 310545 rows (mC sites) and 1346 columns (samples).\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "x = pd.read_pickle(input_path+'x.pkl')\n",
    "y = pd.read_csv(input_path+'y.csv', index_col=0)\n",
    "\n",
    "print(\n",
    "    f' Dataset (df) contains {x.shape[1]} rows (mC sites) and {x.shape[0]} columns (samples).')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will split the data into a training/discovery and testing/validation set.\n",
    "\n",
    "We will use ```y_train``` to denote the training set, and ```y_test``` to denote the testing set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discovery dataset (train) contains 310545 rows (mC sites) and 1142 columns (samples)\n",
      "\n",
      "AAML1031    520\n",
      "AAML0531    508\n",
      "AML05        64\n",
      "AAML03P1     36\n",
      "CCG2961      14\n",
      "\n",
      "Validation dataset (test) contains 310545 rows (mC sites) and 204 columns (samples).\n",
      "\n",
      "AML02    162\n",
      "AML08     42\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split train and test by clinical trial\n",
    "y_train = y[~y['Clinical Trial'].isin(['AML02', 'AML08'])]\n",
    "y_test = y[y['Clinical Trial'].isin(['AML02', 'AML08'])]\n",
    "\n",
    "# Select samples in x that are in y_train\n",
    "x_train = x.loc[y_train.index]\n",
    "x_test = x.loc[y_test.index]\n",
    "\n",
    "\n",
    "print(\n",
    "    f\"Discovery dataset (train) contains {x_train.shape[1]} rows (mC sites) and {x_train.shape[0]} columns (samples)\")\n",
    "print(\n",
    "    f\"\\n{y_train['Clinical Trial'].value_counts(dropna=False).to_string()}\\n\")\n",
    "print(\n",
    "    f\"Validation dataset (test) contains {x_test.shape[1]} rows (mC sites) and {x_test.shape[0]} columns (samples).\")\n",
    "print(f\"\\n{y_test['Clinical Trial'].value_counts(dropna=False).to_string()}\\n\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Correction with pyCombat"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __pyCombat__: a Python tool for batch effects correction in high-throughput molecular data using empirical Bayes methods\n",
    "\n",
    "- __Github__: [https://epigenelabs.github.io/pyComBat/](https://epigenelabs.github.io/pyComBat/)\n",
    "\n",
    "- __Implementation Paper__: [bioRxiv](https://doi.org/10.1101/2020.03.17.995431)\n",
    "\n",
    "- __Original Paper__: [Biostatistics](https://pubmed.ncbi.nlm.nih.gov/16632515/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 batches.\n",
      "Adjusting for 0 covariate(s) or covariate level(s).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardizing Data across genes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting L/S model and finding priors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding parametric adjustments.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting the Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succesfully corrected batch effects in the training dataset.\n"
     ]
    }
   ],
   "source": [
    "from combat.pycombat import pycombat\n",
    "\n",
    "# Correct batch effects in the training dataset\n",
    "x_train2 = pycombat(x_train.T, y_train['Batch']).T\n",
    "\n",
    "print('Succesfully corrected batch effects in the training dataset.')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimension Reduction with PaCMAP"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __PaCMAP__: Large-scale Dimension Reduction Technique Preserving Both Global and Local Structure\n",
    "\n",
    "- __Github__: [https://github.com/YingfanWang/PaCMAP](https://github.com/YingfanWang/PaCMAP)\n",
    "\n",
    "- __Paper__: [Journal of Machine Learning Research](https://jmlr.org/papers/v22/20-1061.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "hide-input",
     "remove-output"
    ]
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pacmap'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpacmap\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_pacmap\u001b[39m(x_train, x_test, n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m):\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;124;03m    Run PaCMAP on the training dataset apply learned parameters to the train and test.\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     23\u001b[0m \n\u001b[0;32m     24\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pacmap'"
     ]
    }
   ],
   "source": [
    "import pacmap\n",
    "\n",
    "\n",
    "def run_pacmap(x_train, x_test, n_components=2):\n",
    "    \"\"\"\n",
    "    Run PaCMAP on the training dataset apply learned parameters to the train and test.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x_train : pandas.DataFrame\n",
    "        Training dataset.\n",
    "    x_test : pandas.DataFrame\n",
    "        Test dataset.\n",
    "    n_components : int, optional\n",
    "        Number of components. The default is 2.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    embedding : numpy.ndarray\n",
    "        Embedding of the training dataset.\n",
    "    embedding_test : numpy.ndarray\n",
    "        Embedding of the test dataset.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize PaCMAP. Note: hyperparameter tuning has been performed.\n",
    "    reducer = pacmap.PaCMAP(n_components=n_components, n_neighbors=15,\n",
    "                            MN_ratio=0.4, FP_ratio=16.0, random_state=42,\n",
    "                            lr=0.1, num_iters=5000)\n",
    "\n",
    "    # Fit (estimate) parameters to the training dataset to learn the embedding\n",
    "    embedding = reducer.fit_transform(x_train)\n",
    "\n",
    "    # Transform (apply) parameters to the test dataset\n",
    "    embedding_test = reducer.transform(x_test, basis=x_train.copy())\n",
    "\n",
    "    return embedding, embedding_test\n",
    "\n",
    "\n",
    "embedding, embedding_test = run_pacmap(x_train2, x_test)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{note}\n",
    "\n",
    "You may have noticed that we called two methods in the PaCMAP class: ```fit``` and ```transform```.\n",
    "\n",
    "- ```fit``` means to learn the parameters of a model _from_ a dataset.\n",
    "\n",
    "- ```transform``` means to apply the learned parameters of a model _to_ a dataset.\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfuly saved 1142 x_train samples and 204 x_test samples.\n",
      "Path: ../Data/Processed_Data/PaCMAP_Results/\n"
     ]
    }
   ],
   "source": [
    "# Transform df to pandas dataframe format\n",
    "embedding = pd.DataFrame(embedding, index=x_train2.index,\n",
    "                         columns=['PaCMAP 1', 'PaCMAP 2'])\n",
    "embedding_test = pd.DataFrame(embedding_test, index=x_test.index,\n",
    "                              columns=['PaCMAP 1', 'PaCMAP 2'])\n",
    "\n",
    "# Save embeddings\n",
    "embedding.to_pickle(output_path+'embedding.pkl')\n",
    "embedding_test.to_pickle(output_path+'embedding_test.pkl')\n",
    "\n",
    "print(\n",
    "    f'Successfuly saved {embedding.shape[0]} x_train samples and {embedding_test.shape[0]} x_test samples.\\nPath: {output_path}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "remove-input",
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python implementation: CPython\n",
      "Python version       : 3.10.9\n",
      "IPython version      : 8.8.0\n",
      "\n",
      "numpy  : 1.23.5\n",
      "pandas : 1.5.2\n",
      "sklearn: 1.2.0\n",
      "combat : 0.3.3\n",
      "pacmap : 0.7.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# produce a list of the loaded modules\n",
    "%watermark -v -p numpy,pandas,sklearn,combat,pacmap"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_pacmap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "7328ddd0773a173f0c44beaff9566ac42c53e8baed6ae05b3a679442944fbd87"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}