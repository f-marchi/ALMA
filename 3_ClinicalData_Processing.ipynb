{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clinical Data Processing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where the data at?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = '../Data/Intermediate_Files/'\n",
    "clinicaldata_path = '../Data/Raw_Data/Clinical_Data/'\n",
    "output_path = '../Data/Processed_Data/'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Methyl Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Dataset (df) contains 333249 columns (mC sites) and 3357 rows (samples).\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_methyl = pd.read_pickle(\n",
    "    input_path+'2_MethylData_Processing_Output.pkl')\n",
    "\n",
    "print(\n",
    "    f' Dataset (df) contains {df_methyl.shape[1]} columns (mC sites) and {df_methyl.shape[0]} rows (samples).')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Batch\n",
       "GSE49031          933\n",
       "GSE190931         581\n",
       "GSE124413         495\n",
       "GSE159907         316\n",
       "GDC_TARGET-AML    314\n",
       "GDC_TCGA-AML      194\n",
       "GSE152710         166\n",
       "GSE147667         153\n",
       "GDC_TARGET-ALL    141\n",
       "GSE133986          64\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_methyl['Batch'].value_counts(dropna=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Labels/Clinical Outcome Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Import functions to clean up clinical data\n",
    "from FM_Functions.Clinical_Data_CleanUp import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Call functions to merge, index and clean clinical data files\n",
    "labels_aml02        = clean_aml02     (merge_index_aml02())\n",
    "labels_aml08        = clean_aml08     (merge_index_aml08())\n",
    "labels_aml05        = clean_aml05     (merge_index_aml05())\n",
    "labels_cog          = clean_cog       (merge_index_cog())\n",
    "labels_beataml      = clean_beataml   (merge_index_beataml())\n",
    "labels_amltcga      = clean_amltcga   (merge_index_amltcga())\n",
    "labels_nordic_all   = clean_nordic_all(merge_index_nordic_all())\n",
    "labels_mds_taml     = clean_mds_taml  (merge_index_mds_taml())\n",
    "labels_all_graal    = clean_all_graal (merge_index_all_graal())\n",
    "\n",
    "\n",
    "# Combine all clinical data labels into one dataframe\n",
    "labels_combined = pd.concat([labels_aml02, labels_aml08, labels_aml05,\n",
    "                        labels_cog, labels_beataml, labels_amltcga,\n",
    "                        labels_nordic_all, labels_mds_taml,\n",
    "                        labels_all_graal], axis=0, join='outer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sample Type\n",
       "Diagnosis    280\n",
       "Relapse       36\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_beataml['Sample Type'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Sample Type'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/projects/MethylScore/Code/.venv_py38/lib/python3.8/site-packages/pandas/core/indexes/base.py:3652\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3651\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3652\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3653\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/projects/MethylScore/Code/.venv_py38/lib/python3.8/site-packages/pandas/_libs/index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/projects/MethylScore/Code/.venv_py38/lib/python3.8/site-packages/pandas/_libs/index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Sample Type'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m labels_amltcga[\u001b[39m'\u001b[39;49m\u001b[39mSample Type\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39mvalue_counts(dropna\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)    \n",
      "File \u001b[0;32m~/projects/MethylScore/Code/.venv_py38/lib/python3.8/site-packages/pandas/core/frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3759\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3760\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3761\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3762\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3763\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/projects/MethylScore/Code/.venv_py38/lib/python3.8/site-packages/pandas/core/indexes/base.py:3654\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3653\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3654\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3655\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3656\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3657\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3658\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3659\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Sample Type'"
     ]
    }
   ],
   "source": [
    "labels_amltcga['Sample Type'].value_counts(dropna=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Remove samples that are not in the methyl dataset\n",
    "df = labels_combined.loc[labels_combined.index.isin(df_methyl.index)]\n",
    "\n",
    "# Label control samples from the AML0531 clinical trial (GSE124413) as 'Bone Marrow Normal'\n",
    "df_ = label_control_samples(df_methyl, df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3357, 333249), (2995, 2149))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_methyl.shape, df_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_cog.to_excel(output_path+'labels_cog.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_beataml.to_excel(output_path+'labels_beataml.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_amltcga.to_excel(output_path+'labels_amltcga.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_nordic_all.to_excel(output_path+'labels_nordic_all.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_mds_taml.to_excel(output_path+'labels_mds_taml.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_tcell_all_graal.to_excel(output_path+'labels_tcell_all_graal.xlsx')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MDS_tAML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = pd.read_pickle('../Data/Raw_Data/Methyl_Array_450k/GSE152710/sample_sheet_meta_data.pkl').iloc[:,:-1].set_index('Sample_ID')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nordic ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load meta data from GSE49031\n",
    "meta = pd.read_pickle('../Data/Raw_Data/Methyl_Array_450k/GSE49031/sample_sheet_meta_data.pkl')\\\n",
    "                        .iloc[:,:-1].set_index('Sample_ID')\n",
    "\n",
    "# split meta `title` column by the last word\n",
    "meta['title'] = meta['title'].str.split().str[-1]\n",
    "\n",
    "# Set index to `title`\n",
    "meta = meta.reset_index().set_index('title')\n",
    "\n",
    "# Load clinical data from paper\n",
    "paper = pd.read_excel('../Data/Raw_Data/Clinical_Data/Nordic_ALL/PMID_25729447_Supp_Clinical_Data.xlsx',\n",
    "                      index_col=0,header=2, sheet_name='Table S7- Verification summary')[['Karyotyping at diagnosisc']]\n",
    "\n",
    "# Join meta and paper\n",
    "meta = meta.join(paper)\n",
    "\n",
    "# Reset index to `Sample_ID`\n",
    "meta = meta.reset_index().set_index('Sample_ID')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tcell_ALL_GRAAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = pd.read_pickle('../Data/Raw_Data/Methyl_Array_EPIC/GSE147667/sample_sheet_meta_data.pkl').iloc[:,:-1].set_index('Sample_ID')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GDC TARGET ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load clinical data from GDC\n",
    "json_clinical_demographic = pd.read_json('../Data/Raw_Data/Methyl_Array_EPIC/GDC_TARGET-ALL/clinical.cases_selection.2023-05-12.json',\n",
    "                            orient='values')\n",
    "\n",
    "# flatten json\n",
    "json_clinical_demographic = pd.json_normalize(json_clinical_demographic['demographic'].dropna())\n",
    "\n",
    "# extract the second to last term from the `submitter_id` column\n",
    "json_clinical_demographic['submitter_id'] = json_clinical_demographic['submitter_id'].str.split('-').str[-1]\n",
    "\n",
    "# extract the first term from the `submitter_id` column by `_`\n",
    "json_clinical_demographic['submitter_id'] = json_clinical_demographic['submitter_id'].str.split('_').str[0]\n",
    "\n",
    "# change `submitter_id` column name to `Patient_ID`\n",
    "json_clinical_demographic = json_clinical_demographic.rename(columns={'submitter_id':'Patient_ID'})\n",
    "\n",
    "# Set index to `submitter_id`\n",
    "json_clinical_demographic = json_clinical_demographic.set_index('demographic_id')['Patient_ID']\n",
    "\n",
    "# Load clinical data from GDC\n",
    "clinical_tsv = pd.read_csv('../Data/Raw_Data/Methyl_Array_EPIC/GDC_TARGET-ALL/clinical.tsv', \n",
    "                            sep='\\t', index_col=0)\n",
    "\n",
    "# Extract the last word from the `case_submitter_id` column by splitting by `-`\n",
    "clinical_tsv['Patient_ID'] = clinical_tsv['case_submitter_id'].str.split('-').str[-1]\n",
    "\n",
    "clinical_tsv = clinical_tsv['Patient_ID']\n",
    "\n",
    "# concat clinical_tsv and json_clinical_demographic\n",
    "clinical = pd.concat([clinical_tsv, json_clinical_demographic], axis=0, join='outer')\n",
    "\n",
    "# Set index to `Patient_ID`\n",
    "clinical = clinical.reset_index().set_index('Patient_ID')\n",
    "\n",
    "# Load clinical data from paper\n",
    "paper = pd.read_excel('../Data/Raw_Data/Clinical_Data/ALL_P3_TARGET/41586_2018_436_MOESM4_ESM.xlsx',\n",
    "                      sheet_name='ST2 Cohort', index_col=0)\n",
    "\n",
    "# # Join clinical data from paper and GDC\n",
    "labels_alltarget = clinical.join(paper, how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = pd.read_pickle('../Data/Raw_Data/Methyl_Array_EPIC/GDC_TARGET-ALL/sample_sheet_meta_data.pkl').set_index('Sentrix_ID')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TCGA AML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_index_amltcga():\n",
    "\n",
    "    # load clinical data from GDC\n",
    "    clinical_tsv = pd.read_csv('../Data/Raw_Data/Methyl_Array_450k/GDC_TCGA-AML/clinical.tsv', \n",
    "                    sep='\\t', index_col=0)[['case_submitter_id']].drop_duplicates()\n",
    "\n",
    "    # extract last 4 digits from case_id to get TCGA Patient ID\n",
    "    clinical_tsv['TCGA Patient ID'] = clinical_tsv['case_submitter_id'].str[-4:]\n",
    "\n",
    "    # set index to TCGA Patient ID\n",
    "    clinical_tsv = clinical_tsv.reset_index().set_index('TCGA Patient ID').sort_index()\n",
    "\n",
    "    # load meta data from NEJM 2013 paper\n",
    "    meta = pd.read_excel('../Data/Raw_Data/Clinical_Data/TCGA_LAML/SuppTable01_NEJM2013_TCGA_AML.Paper_Mutation data.xlsx',\n",
    "                        index_col=1).iloc[1:,:].sort_index()\n",
    "\n",
    "    # make meta index integers\n",
    "    meta.index = meta.index.astype(int)\n",
    "    clinical_tsv.index = clinical_tsv.index.astype(int)\n",
    "\n",
    "    # join clinical_tsv and meta\n",
    "    labels_amltcga = clinical_tsv.join(meta, how='left')\n",
    "\n",
    "    # set index to case_id\n",
    "    labels_amltcga = labels_amltcga.reset_index().set_index('case_id')\n",
    "    \n",
    "    return labels_amltcga\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BeatAML Clinical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def merge_index_beataml ():\n",
    "    meta = pd.read_pickle('../Data/Raw_Data/Methyl_Array_EPIC/GSE159907/sample_sheet_meta_data.pkl').iloc[:,:-1]\n",
    "\n",
    "    # Create a new column with only the content inside [] from column 'Sample_Name'\n",
    "    meta['LLS_SampleID'] = meta['Sample_Name'].str.extract(r\"\\[(.*?)\\]\", expand=False)\n",
    "\n",
    "    # Set the index to the new column\n",
    "    meta1 = meta[['tissue','disease_state','LLS_SampleID','Sample_ID']].set_index('LLS_SampleID')\n",
    "\n",
    "    # Read in the clinical data\n",
    "    meta2 = pd.read_excel('../Data/Raw_Data/Clinical_Data/BeatAML/BEAT_AML_Raw clinical data_702.Samples.Vizome.xlsx', index_col=3)\n",
    "\n",
    "    # Join the two dataframes\n",
    "    labels_beataml = meta1.join(meta2, how='left').reset_index().set_index('Sample_ID')\n",
    "\n",
    "    return labels_beataml\n",
    "\n",
    "labels_beataml = clean_beataml()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3c02342a",
   "metadata": {},
   "source": [
    "## Remove Samples based on Certain Clinical Features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Relapse Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41f406b9",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 1762 samples, 248 matched, yielding 1514 samples after filtering\n"
     ]
    }
   ],
   "source": [
    "df1 = df_[~df_['Sample Type'].isin(['Relapse', 'Recurrent Blood Derived Cancer - Bone Marrow',\n",
    "                                    'Recurrent Blood Derived Cancer - Peripheral Blood'])]\n",
    "\n",
    "print(\n",
    "    f'Out of {df_.shape[0]} samples, {df_.shape[0]-df1.shape[0]} matched, yielding {df1.shape[0]} samples after filtering')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Control/Normal Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 1514 samples, 154 matched, yielding 1360 samples after filtering\n"
     ]
    }
   ],
   "source": [
    "df2 = df1[~df1['Sample Type'].isin(\n",
    "    ['Bone Marrow Normal', 'Blood Derived Normal'])]\n",
    "print(\n",
    "    f'Out of {df1.shape[0]} samples, {df1.shape[0]-df2.shape[0]} matched, yielding {df2.shape[0]} samples after filtering')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Duplicate Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 1360 samples, 14 matched, yielding 1346 samples after filtering\n"
     ]
    }
   ],
   "source": [
    "df3 = df2[~df2['Patient_ID'].duplicated(keep='last')]\n",
    "print(\n",
    "    f'Out of {df2.shape[0]} samples, {df2.shape[0]-df3.shape[0]} matched, yielding {df3.shape[0]} samples after filtering')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "39875e9e",
   "metadata": {},
   "source": [
    "## Save Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "output = df3.join(df_methyl,how='left') # Join clinical data with methyl data\n",
    "\n",
    "x = output.iloc[:,df3.shape[1]+1:] # Select only methyl data\n",
    "y = output.iloc[:,0:df3.shape[1]+1] # Select only clinical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discovery dataset (train) contains 310545 rows (5mC sites) and 1142 columns (samples)\n",
      "\n",
      "AAML1031    520\n",
      "AAML0531    508\n",
      "AML05        64\n",
      "AAML03P1     36\n",
      "CCG2961      14\n",
      "\n",
      "Validation dataset (test) contains 310545 rows (5mC sites) and 204 columns (samples).\n",
      "\n",
      "AML02    162\n",
      "AML08     42\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split train and test by clinical trial\n",
    "y_train = y[~y['Clinical Trial'].isin(['AML02', 'AML08'])]\n",
    "# y_train = y_train[y_train['Sample Type'].isin(['Diagnosis',\n",
    "#        'Primary Blood Derived Cancer - Bone Marrow', 'Bone Marrow Normal',\n",
    "#        'Primary Blood Derived Cancer - Peripheral Blood',\n",
    "#        'Blood Derived Normal'])]\n",
    "\n",
    "y_test = y[y['Clinical Trial'].isin(['AML02', 'AML08'])]\n",
    "\n",
    "# Select samples in x that are in y_train\n",
    "x_train = x.loc[y_train.index]\n",
    "x_test = x.loc[y_test.index]\n",
    "\n",
    "# x_train = pd.concat([x_train, ctrl_x], axis=0)\n",
    "# y_train = pd.concat([y_train, ctrl_y], axis=0,keys=['Diagnosis','Control'], names=['sample_type'])\n",
    "\n",
    "\n",
    "print(\n",
    "    f\"Discovery dataset (train) contains {x_train.shape[1]} rows (5mC sites) and {x_train.shape[0]} columns (samples)\")\n",
    "print(\n",
    "    f\"\\n{y_train['Clinical Trial'].value_counts(dropna=False).to_string()}\\n\")\n",
    "print(\n",
    "    f\"Validation dataset (test) contains {x_test.shape[1]} rows (5mC sites) and {x_test.shape[0]} columns (samples).\")\n",
    "print(f\"\\n{y_test['Clinical Trial'].value_counts(dropna=False).to_string()}\\n\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Correction with pyCombat"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __pyCombat__: a Python tool for batch effects correction in high-throughput molecular data using empirical Bayes methods\n",
    "\n",
    "- __Github__: [https://epigenelabs.github.io/pyComBat/](https://epigenelabs.github.io/pyComBat/)\n",
    "\n",
    "- __Implementation Paper__: [bioRxiv](https://doi.org/10.1101/2020.03.17.995431)\n",
    "\n",
    "- __Original Paper__: [Biostatistics](https://pubmed.ncbi.nlm.nih.gov/16632515/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 batches.\n",
      "Adjusting for 0 covariate(s) or covariate level(s).\n",
      "Standardizing Data across genes.\n",
      "Fitting L/S model and finding priors.\n",
      "Finding parametric adjustments.\n",
      "Adjusting the Data\n",
      "Succesfully corrected batch effects in the training dataset.\n"
     ]
    }
   ],
   "source": [
    "from combat.pycombat import pycombat\n",
    "\n",
    "# Correct batch effects in the training dataset\n",
    "x_train2 = pycombat(x_train.T, y_train['Batch']).T\n",
    "\n",
    "print('Succesfully corrected batch effects in the training dataset.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discovery dataset (train) contains 310545 rows (5mC sites) and 1078 columns (samples)\n",
      "\n",
      "AAML1031    520\n",
      "AAML0531    508\n",
      "AAML03P1     36\n",
      "CCG2961      14\n",
      "\n",
      "Validation dataset (test) contains 310545 rows (5mC sites) and 204 columns (samples).\n",
      "\n",
      "AML02    162\n",
      "AML08     42\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_train = y_train[~y_train['Clinical Trial'].isin(['AML05'])]\n",
    "x_train3 = x_train2.loc[y_train.index]\n",
    "\n",
    "\n",
    "print(\n",
    "    f\"Discovery dataset (train) contains {x_train3.shape[1]} rows (5mC sites) and {x_train3.shape[0]} columns (samples)\")\n",
    "print(\n",
    "    f\"\\n{y_train['Clinical Trial'].value_counts(dropna=False).to_string()}\\n\")\n",
    "print(\n",
    "    f\"Validation dataset (test) contains {x_test.shape[1]} rows (5mC sites) and {x_test.shape[0]} columns (samples).\")\n",
    "print(f\"\\n{y_test['Clinical Trial'].value_counts(dropna=False).to_string()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfuly saved methyl data in x.pkl and clinical data in y.csv.\n",
      "Path: ../Data/Processed_Data/\n"
     ]
    }
   ],
   "source": [
    "x_train3.to_pickle(output_path+'x_train.pkl') # Save methyl data\n",
    "y_train.to_csv(output_path+'y_train.csv') # Save clinical data\n",
    "\n",
    "print(\n",
    "    f'Successfuly saved methyl data in x.pkl and clinical data in y.csv.\\nPath: {output_path}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Control and Relapse Data Separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfuly saved 147 control samples and 248 relapse samples.\n",
      "Path: ../Data/Processed_Data/\n"
     ]
    }
   ],
   "source": [
    "controls = df_[df_['Sample Type'].isin(['Bone Marrow Normal'])]\n",
    "\n",
    "relapse = df_[df_['Sample Type'].isin(['Relapse', 'Recurrent Blood Derived Cancer - Bone Marrow',\n",
    "                                       'Recurrent Blood Derived Cancer - Peripheral Blood'])]\n",
    "\n",
    "# Merge control and relapse samples\n",
    "t = pd.concat([controls, relapse], axis=0, join='outer',\n",
    "              names=['Control', 'Relapse'])\n",
    "\n",
    "# Join clinical data with methyl data\n",
    "t2 = df_methyl.join(t, how='right')\n",
    "\n",
    "# Save merged control and relapse samples\n",
    "t2.to_pickle(output_path+'control_relapse.pkl')\n",
    "\n",
    "print(\n",
    "    f'Successfuly saved {controls.shape[0]} control samples and {relapse.shape[0]} relapse samples.\\nPath: {output_path}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": [
     "remove-input",
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python implementation: CPython\n",
      "Python version       : 3.10.10\n",
      "IPython version      : 8.3.0\n",
      "\n",
      "pandas: 1.5.3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# produce a list of the loaded modules\n",
    "%watermark -v -p pandas"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": ".venv_data_vizualization",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "1536c79f85cc2a2ac13c148ca716b8e28acb6745983d6aacea6d4fcb49ea6e2e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
