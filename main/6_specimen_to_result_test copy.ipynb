{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specimen testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`modkit pileup kasumi1_naive.bam kasumi1_pileup_cpg.bed --combine-mods --log-filepath pileup.log --no-filtering -t 32 --combine-strands --cpg --ref GCA_000001405.15_GRCh38_no_alt_analysis_set.fna`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where data at?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "mount = '/mnt/e/'\n",
    "# input_path = mount + 'MethylScore/Nanopore_data/Kasumi1-naive-p2solo.bed.gz'\n",
    "# input_path = '/mnt/h/UF_HemBank_1852/SAMPLE_ungrouped.wf_mods.bedmethyl.gz'\n",
    "# input_path = '/mnt/h/epi2me_analyses/uf_hembank_1832_wf-human-variation_01HQG462AJKW6RH7XCFBQPD54E/output/UF_HemBank_1832_ungrouped.wf_mods.bedmethyl.gz'\n",
    "input_path = '~/projects/modkit_runs/kasumi1_pileup_cpg_pacmap.bed'\n",
    "reference_path = mount + 'genome_references/Illumina_methylation_arrays/EPIC.anno.GRCh38.tsv.gz'\n",
    "output_path = mount + 'MethylScore_v2/Processed_Data/'\n",
    "\n",
    "sample_name = 'kasumi1_naive'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Harmonize probes from EPIC array with nanopore methylation calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# read df_discovery and df_validation\n",
    "# df_discovery = pd.read_pickle(mount+'MethylScore/Intermediate_Files/'+'3308samples_333059cpgs_withbatchcorrection_bvalues.pkl').sort_index().iloc[:,1:]\n",
    "# array_reference = pd.read_csv(reference_path, sep='\\t', usecols=['chrm','start','end','probeID']).set_index('probeID')\n",
    "# array_reference['coordinate'] = array_reference['chrm'].astype(str) + ':' + array_reference['start'].astype(str)\n",
    "# pacmap_reference = array_reference.loc[df_discovery.columns]\n",
    "# pacmap_reference.to_pickle(mount+'MethylScore/Intermediate_Files/'+'pacmap_probe_reference.pkl')\n",
    "\n",
    "# load the reference data\n",
    "pacmap_reference = pd.read_pickle(mount+'MethylScore_v2/Intermediate_Files/'+'pacmap_probe_reference.pkl').reset_index().set_index('coordinate')\n",
    "\n",
    "# Save `pacmap_reference` as a .bed file\n",
    "# pacmap_reference[['chrm', 'start', 'end',]].to_csv('~/projects/modkit_runs/pacmap_reference.bed', sep='\\t', header=False, index=False)\n",
    "\n",
    "# Define columns to be used for the input data\n",
    "usecols = [0, 1, 4, 10]\n",
    "column_names = [\"chrom\", \"start_position\", \"score\", \"fraction_modified\"]\n",
    "\n",
    "# Read the input data, skipping the first row if it's a header or irrelevant\n",
    "df = pd.read_csv(input_path, sep='\\s+', skiprows=1, names=column_names, usecols=usecols)\n",
    "\n",
    "# Create 'coordinate' column for merging\n",
    "df['coordinate'] = df['chrom'].astype(str) + ':' + df['start_position'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df.set_index('coordinate')\n",
    "\n",
    "# Join with reference data on 'coordinate'\n",
    "df_merged = df_filtered.join(pacmap_reference, how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Interpolate missing values in 'fraction_modified' column linearly\n",
    "df_merged['fraction_modified'] = df_merged['fraction_modified'].astype(float).interpolate(method='linear')\n",
    "\n",
    "df_merged = df_merged[['fraction_modified']].join(pacmap_reference, how='inner')\n",
    "\n",
    "df_merged = df_merged.drop_duplicates(subset='IlmnID')\n",
    "\n",
    "# Calculate the fraction_modified and prepare the final DataFrame\n",
    "df_merged.loc[:, sample_name] = (df_merged['fraction_modified'] / 100).round(3)\n",
    "\n",
    "df_processed = df_merged[['IlmnID', sample_name]].set_index('IlmnID').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the reference data\n",
    "pacmap_reference = pd.read_pickle(mount+'MethylScore/Intermediate_Files/'+'pacmap_probe_reference.pkl').reset_index().set_index('coordinate')\n",
    "\n",
    "# Define columns to be used for the input data\n",
    "usecols = [0, 1, 3, 10]\n",
    "column_names = [\"chrom\", \"start_position\", \"modified_base_code\", \"fraction_modified\"]\n",
    "\n",
    "# Read the input data, skipping the first row if it's a header or irrelevant\n",
    "df = pd.read_csv(input_path, sep='\\s+', skiprows=1, names=column_names, usecols=usecols)\n",
    "\n",
    "# Create 'coordinate' column for merging\n",
    "df['coordinate'] = df['chrom'].astype(str) + ':' + df['start_position'].astype(str)\n",
    "\n",
    "# Filter for 'm' and 'h' modified base codes before merging\n",
    "df_filtered = df[df['modified_base_code'].isin(['m'])].set_index('coordinate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_reference = pd.read_csv(reference_path, sep='\\t', usecols=['chrm','start','end','probeID']).set_index('probeID')\n",
    "array_reference['coordinate'] = array_reference['chrm'].astype(str) + ':' + array_reference['start'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>probeID</th>\n",
       "      <th>cg14817997</th>\n",
       "      <th>cg26928153</th>\n",
       "      <th>cg16269199</th>\n",
       "      <th>cg13869341</th>\n",
       "      <th>cg14008030</th>\n",
       "      <th>cg18231760</th>\n",
       "      <th>cg20253340</th>\n",
       "      <th>cg02404219</th>\n",
       "      <th>cg04098293</th>\n",
       "      <th>cg24335620</th>\n",
       "      <th>...</th>\n",
       "      <th>cg00491786</th>\n",
       "      <th>cg07587934</th>\n",
       "      <th>cg16855331</th>\n",
       "      <th>cg05740793</th>\n",
       "      <th>cg20450977</th>\n",
       "      <th>cg11894324</th>\n",
       "      <th>cg24159721</th>\n",
       "      <th>cg05001044</th>\n",
       "      <th>cg08858441</th>\n",
       "      <th>cg03348902</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>UF_HemBank_1832</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 204711 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "probeID          cg14817997  cg26928153  cg16269199  cg13869341  cg14008030  \\\n",
       "UF_HemBank_1832         0.0         1.0         0.0         1.0         0.0   \n",
       "\n",
       "probeID          cg18231760  cg20253340  cg02404219  cg04098293  cg24335620  \\\n",
       "UF_HemBank_1832         0.0         1.0         0.0         1.0         1.0   \n",
       "\n",
       "probeID          ...  cg00491786  cg07587934  cg16855331  cg05740793  \\\n",
       "UF_HemBank_1832  ...         1.0       0.333         0.0         0.0   \n",
       "\n",
       "probeID          cg20450977  cg11894324  cg24159721  cg05001044  cg08858441  \\\n",
       "UF_HemBank_1832         0.0         0.0         0.0       0.001         0.0   \n",
       "\n",
       "probeID          cg03348902  \n",
       "UF_HemBank_1832       0.001  \n",
       "\n",
       "[1 rows x 204711 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge the two dataframes\n",
    "df_5mc_merged = pd.merge(df_filtered, array_reference.reset_index()[['probeID','coordinate']], on='coordinate', how='inner')\n",
    "\n",
    "# Set the index to the probeID\n",
    "df_5mc_merged = df_5mc_merged.set_index('probeID')\n",
    "\n",
    "# Create beta values column\n",
    "df_5mc_merged[sample_name] = (df_5mc_merged['fraction_modified'] / 100).round(3)\n",
    "\n",
    "# Create a new dataframe with only the beta values\n",
    "df_nanopore = df_5mc_merged[[sample_name]].T\n",
    "\n",
    "df_nanopore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_discovery = pd.read_pickle(mount+'MethylScore/Intermediate_Files/'+'3308samples_333059cpgs_withbatchcorrection_bvalues.pkl').sort_index().iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use overlapping features between df_discovery and df_nanopore\n",
    "common_features = [x for x in df_discovery.columns if x in df_nanopore.columns]\n",
    "\n",
    "# apply `common_features` to both df_discovery and df_nanopore\n",
    "df_discovery = df_discovery[common_features]\n",
    "df_nanopore = df_nanopore[common_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PaCMAP version: 0.7.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fmarchi/projects/AML-atlas-notebooks/.venv/lib/python3.8/site-packages/pacmap/pacmap.py:819: UserWarning: Warning: random state is set to 42\n",
      "  warnings.warn(f'Warning: random state is set to {_RANDOM_STATE}')\n"
     ]
    }
   ],
   "source": [
    "import pacmap\n",
    "print('PaCMAP version:', pacmap.__version__)\n",
    "\n",
    "components_list = [5]\n",
    "for components in components_list:\n",
    "    \n",
    "    reducer = pacmap.PaCMAP(n_components=components, \n",
    "                            n_neighbors=10, \n",
    "                            MN_ratio=0.4, \n",
    "                            FP_ratio=16.0, \n",
    "                            lr=0.1, \n",
    "                            num_iters=5000,\n",
    "                            random_state=42,\n",
    "                            save_tree=True)\n",
    "\n",
    "    # Project the high dimensional dataset into a low-dimensional embedding\n",
    "    embedding_training = reducer.fit_transform(df_discovery.to_numpy(dtype='float16'))\n",
    "\n",
    "    # Save reducer\n",
    "    # pacmap.save(reducer, f'../models/pacmap_{components}d_model_al_atlas')\n",
    "\n",
    "    # Create column names\n",
    "    cols = ['PaCMAP '+ str(i+1) + f' of {components}' for i in range(components)]\n",
    "\n",
    "    # Turn embedding into dataframe\n",
    "    df_embedding = pd.DataFrame(embedding_training, columns=cols, index=df_discovery.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply PaCMAP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import pacmap\n",
    "\n",
    "def apply_pacmap_model_to_new_data(df, components, reducer=reducer):\n",
    "\n",
    "    # Project the high dimensional dataset into existing embedding space and return the embedding.\n",
    "    embedding = reducer.transform(df.to_numpy(dtype='float16'))\n",
    "\n",
    "    # Create column names\n",
    "    cols = ['PaCMAP '+ str(i+1) + f' of {components}' for i in range(components)]\n",
    "\n",
    "    # Turn embedding into dataframe\n",
    "    df_embedding = pd.DataFrame(embedding, columns=cols, index=df.index)\n",
    "\n",
    "    return df_embedding\n",
    "\n",
    "\n",
    "df_embedding_5d = apply_pacmap_model_to_new_data(df_nanopore, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PaCMAP 1 of 5</th>\n",
       "      <th>PaCMAP 2 of 5</th>\n",
       "      <th>PaCMAP 3 of 5</th>\n",
       "      <th>PaCMAP 4 of 5</th>\n",
       "      <th>PaCMAP 5 of 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>UF_HemBank_1832</th>\n",
       "      <td>-13.868196</td>\n",
       "      <td>-15.072299</td>\n",
       "      <td>13.773742</td>\n",
       "      <td>-22.246822</td>\n",
       "      <td>10.254135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 PaCMAP 1 of 5  PaCMAP 2 of 5  PaCMAP 3 of 5  PaCMAP 4 of 5  \\\n",
       "UF_HemBank_1832     -13.868196     -15.072299      13.773742     -22.246822   \n",
       "\n",
       "                 PaCMAP 5 of 5  \n",
       "UF_HemBank_1832      10.254135  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_embedding_5d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pacmap\n",
    "\n",
    "# def apply_pacmap_model_to_new_data(df, components):\n",
    "\n",
    "#     # Load reducer\n",
    "#     reducer = pacmap.load(f'../models/pacmap_{components}d_model_al_atlas')\n",
    "\n",
    "#     # Project the high dimensional dataset into existing embedding space and return the embedding.\n",
    "#     embedding = reducer.transform(df.to_numpy(dtype='float16'))\n",
    "\n",
    "#     # Create column names\n",
    "#     cols = ['PaCMAP '+ str(i+1) + f' of {components}' for i in range(components)]\n",
    "\n",
    "#     # Turn embedding into dataframe\n",
    "#     df_embedding = pd.DataFrame(embedding, columns=cols, index=df.index)\n",
    "\n",
    "#     return df_embedding\n",
    "\n",
    "# df_embedding_2d = apply_pacmap_model_to_new_data(df_processed, 2)\n",
    "# df_embedding_5d = apply_pacmap_model_to_new_data(df_processed, 5)\n",
    "\n",
    "# df_embedding_2d.to_pickle(output_path + sample_name + '_pacmap_2d.pkl')\n",
    "# df_embedding_5d.to_pickle(output_path + sample_name + '_pacmap_5d.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply supervised models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AML Epigenomic Risk</th>\n",
       "      <th>AML Epigenomic Risk P(High Risk)</th>\n",
       "      <th>AL Epigenomic Phenotype</th>\n",
       "      <th>P(T-ALL NOS)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>UF_HemBank_1832</th>\n",
       "      <td>High</td>\n",
       "      <td>0.546</td>\n",
       "      <td>T-ALL NOS</td>\n",
       "      <td>0.969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                AML Epigenomic Risk  AML Epigenomic Risk P(High Risk)  \\\n",
       "UF_HemBank_1832                High                             0.546   \n",
       "\n",
       "                AL Epigenomic Phenotype  P(T-ALL NOS)  \n",
       "UF_HemBank_1832               T-ALL NOS         0.969  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Load models\n",
    "lgbm_px_model = joblib.load('../models/lgbm_px_model.pkl')\n",
    "lgbm_dx_model = joblib.load('../models/lgbm_dx_model.pkl')\n",
    "\n",
    "# load `df_embedding_5d` from the previous step\n",
    "df_embedding_5d = pd.read_pickle(output_path + sample_name + '_pacmap_5d.pkl')\n",
    "\n",
    "def save_predictions(df, classifier, model_name):\n",
    "\n",
    "    # ignore sklearn warnings\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "\n",
    "    # Select necessary columns\n",
    "    df_features = df.copy()\n",
    "\n",
    "    # Predict using the selected columns\n",
    "    predictions = classifier.predict(df_features)\n",
    "\n",
    "    # Predict probabilities using the selected columns\n",
    "    probabilities = classifier.predict_proba(df_features)\n",
    "\n",
    "    # Convert predictions to a Series with the same index as df_features\n",
    "    predictions_series = pd.Series(predictions, index=df_features.index, name=model_name)\n",
    "\n",
    "    # Convert probabilities to a DataFrame with the same index as df_features and the same columns as the classes\n",
    "    probabilities_df = pd.DataFrame(probabilities, index=df_features.index, columns=classifier.classes_).round(3)\n",
    "\n",
    "    # Add \" - predict_proba\" to the column names\n",
    "    probabilities_df.columns ='P(' + probabilities_df.columns + ')'\n",
    "\n",
    "    # Transform classes of the predictions into integers based on unique values in the classes\n",
    "    probabilities_df[model_name + '_int'] = predictions_series.map({c: i for i, c in enumerate(classifier.classes_)})\n",
    "\n",
    "    # Join predictions with the original DataFrame (already indexed)\n",
    "    df_joined = predictions_series.to_frame().join(probabilities_df)\n",
    "\n",
    "    return df_joined\n",
    "\n",
    "# Execution\n",
    "df_pred_px = save_predictions(df=df_embedding_5d, classifier=lgbm_px_model, model_name='AML Epigenomic Risk')\n",
    "df_pred_dx = save_predictions(df=df_embedding_5d, classifier=lgbm_dx_model, model_name='AL Epigenomic Phenotype')\n",
    "\n",
    "# Map the classes to more desirable labels (low and high risk)\n",
    "df_pred_px['AML Epigenomic Risk'] = df_pred_px['AML Epigenomic Risk'].map({'Alive': 'Low', 'Dead': 'High'})\n",
    "df_pred_px = df_pred_px.rename(columns={'P(Alive)': 'AML Epigenomic Risk P(Low Risk)', 'P(Dead)': 'AML Epigenomic Risk P(High Risk)'})\n",
    "\n",
    "# Join predictions with clinical data\n",
    "df_combined = df_embedding_2d.join(df_embedding_5d).join(df_pred_px).join(df_pred_dx)\n",
    "\n",
    "df_combined[['AML Epigenomic Risk', 'AML Epigenomic Risk P(High Risk)', 'AL Epigenomic Phenotype', f'P({df_combined[\"AL Epigenomic Phenotype\"].item()})']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EWASCox-Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuous score cut at the value of 0.4934\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>IlmnID</th>\n",
       "      <th>EWASCox_OS_48CpGs</th>\n",
       "      <th>EWASCox_OS_48CpGs Categorical</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>UF_HemBank_1832</th>\n",
       "      <td>3.236585</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "IlmnID           EWASCox_OS_48CpGs EWASCox_OS_48CpGs Categorical\n",
       "UF_HemBank_1832           3.236585                          High"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from source.cox_lasso import *\n",
    "\n",
    "raw_coefs = pd.read_csv(output_path + 'multivariate_cox_lasso/ewas_cog_os_raw_coefs_newrisk.csv', index_col=0)\n",
    "\n",
    "mean_coefs = set_cutoff(coefs=raw_coefs,threshold=0.99)\n",
    "\n",
    "df_validation = df_processed[mean_coefs.index]\n",
    "\n",
    "df_validation_transformed = df_validation.replace(1, 0.999).replace(0, 0.001)\n",
    "\n",
    "def beta2m(val):\n",
    "    '''Transfrom beta-values into m-values'''\n",
    "    return math.log2(val/(1-val))\n",
    "\n",
    "x_test_m = df_validation_transformed.apply(np.vectorize(beta2m))\n",
    "\n",
    "def standardize_data(df, reference_df):\n",
    "    \"\"\"Standardize data using mean and standard deviation of reference dataset\"\"\"\n",
    "\n",
    "    # Keep only columns that are in both datasets\n",
    "    reference_df = reference_df.loc[:, df.columns]\n",
    "\n",
    "    # Standardize data\n",
    "    df_z = (df - reference_df.mean()) / reference_df.std()\n",
    "\n",
    "    return df_z\n",
    "\n",
    "# Read top CpGs selected from previous code file (univariate cox-ph EWAS)\n",
    "ewas_top_cpgs = pd.read_csv(output_path+'ewas_dmr/ewas_top_cpgs_os.csv', index_col=0)\n",
    "\n",
    "# Standardize data\n",
    "x_test_m_z = standardize_data(df= x_test_m, reference_df= ewas_top_cpgs)\n",
    "\n",
    "score_name = 'EWASCox_OS_48CpGs'\n",
    "\n",
    "df_test, threshold = generate_coxph_score(coef_mean=mean_coefs,\n",
    "                                        x=x_test_m_z,\n",
    "                                        df=df_validation_transformed,\n",
    "                                        score_name=score_name,\n",
    "                                        train_test=0.4934,\n",
    "                                        rpart_outcome='os.time')\n",
    "\n",
    "df_validation_transformed[['EWASCox_OS_48CpGs','EWASCox_OS_48CpGs Categorical']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "df_nanopore = df_combined.join(df_validation_transformed[['EWASCox_OS_48CpGs','EWASCox_OS_48CpGs Categorical']])\n",
    "\n",
    "df_nanopore['Train-Test'] = 'Long-read Nanopore sequencing'\n",
    "df_nanopore['Clinical Trial'] = 'UF Hem Bank'\n",
    "df_nanopore['Patient_ID'] = sample_name\n",
    "df_nanopore['Hematopoietic Entity'] = np.nan\n",
    "df_nanopore['WHO 2022 Diagnosis'] =  np.nan\n",
    "df_nanopore['Vital Status'] = np.nan\n",
    "df_nanopore['Risk Group AAML1831'] = np.nan\n",
    "\n",
    "df_nanopore.to_excel(output_path + sample_name + '_processed.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": [
     "remove-input",
     "remove-output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The watermark extension is already loaded. To reload it, use:\n",
      "  %reload_ext watermark\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Francisco_Marchi@Lamba_Lab_UF\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.8.16\n",
      "IPython version      : 8.12.3\n",
      "\n",
      "numpy   : 1.24.4\n",
      "pandas  : 2.0.3\n",
      "pacmap  : 0.7.0\n",
      "sklearn : 1.2.2\n",
      "lightgbm: 3.3.5\n",
      "\n",
      "Compiler    : GCC 11.3.0\n",
      "OS          : Linux\n",
      "Release     : 5.15.133.1-microsoft-standard-WSL2\n",
      "Machine     : x86_64\n",
      "Processor   : x86_64\n",
      "CPU cores   : 8\n",
      "Architecture: 64bit\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# watermark with all libraries used in this notebook\n",
    "%watermark -v -p numpy,pandas,pacmap,sklearn,lightgbm -a Francisco_Marchi@Lamba_Lab_UF -d -m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{note}\n",
    "Please only use the following versions:\n",
    "`python`: 3.8.16\n",
    "`pacmap`: 0.7.0\n",
    "`lightgbm`: 3.3.5\n",
    "`scikit-learn`: 1.2.2\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
