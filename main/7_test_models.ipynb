{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run epigenomic models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{note}\n",
    "Please only use the following versions:\n",
    "`python`: 3.8.16\n",
    "`pacmap`: 0.7.0\n",
    "`lightgbm`: 3.3.5\n",
    "`scikit-learn`: 1.2.2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where the data at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "mount = '/mnt/e/'\n",
    "\n",
    "input_path = mount + 'MethylScore_v2/Intermediate_Files/'\n",
    "output_path = mount + 'MethylScore_v2/Processed_Data/'\n",
    "\n",
    "nanopore_path = mount + 'nanopore_processed/pacmap/'\n",
    "\n",
    "sample_name = 'uf_hembank_1852'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Nanopore dataset (df_nanopore) contains 331886 columns (5mC nucleotides/probes) and 1 rows (samples).\n",
      " Discovery dataset (df_discovery) contains 331886 columns (5mC nucleotides/probes) and 3307 rows (samples).\n"
     ]
    }
   ],
   "source": [
    "df_nanopore = pd.read_pickle(\n",
    "    nanopore_path + sample_name + '_pacmap_bvalues.pkl').sort_index()\n",
    "\n",
    "print(\n",
    "f' Nanopore dataset (df_nanopore) contains {df_nanopore.shape[1]} \\\n",
    "columns (5mC nucleotides/probes) and {df_nanopore.shape[0]} rows (samples).')\n",
    "\n",
    "df_discovery = pd.read_pickle(\n",
    "    input_path+'3308samples_333059cpgs_withbatchcorrection_bvalues.pkl').sort_index().iloc[:,1:][df_nanopore.columns]\n",
    "\n",
    "print(\n",
    "f' Discovery dataset (df_discovery) contains {df_discovery.shape[1]} \\\n",
    "columns (5mC nucleotides/probes) and {df_discovery.shape[0]-1} rows (samples).')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce dimensionality with PaCMAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set hyperparameters, fit, and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PaCMAP version: 0.7.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marchi/projects/AL_atlas_notebooks/.venv_py38/lib/python3.8/site-packages/pacmap/pacmap.py:819: UserWarning: Warning: random state is set to 42\n",
      "  warnings.warn(f'Warning: random state is set to {_RANDOM_STATE}')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The PaCMAP instance is successfully saved at /mnt/e/nanopore_processed/pacmap/uf_hembank_1852_pacmap_2d_model_al_atlas.pkl, and the Annoy Index is saved at /mnt/e/nanopore_processed/pacmap/uf_hembank_1852_pacmap_2d_model_al_atlas.ann.\n",
      "To load the instance again, please do `pacmap.load(/mnt/e/nanopore_processed/pacmap/uf_hembank_1852_pacmap_2d_model_al_atlas)`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marchi/projects/AL_atlas_notebooks/.venv_py38/lib/python3.8/site-packages/pacmap/pacmap.py:819: UserWarning: Warning: random state is set to 42\n",
      "  warnings.warn(f'Warning: random state is set to {_RANDOM_STATE}')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The PaCMAP instance is successfully saved at /mnt/e/nanopore_processed/pacmap/uf_hembank_1852_pacmap_5d_model_al_atlas.pkl, and the Annoy Index is saved at /mnt/e/nanopore_processed/pacmap/uf_hembank_1852_pacmap_5d_model_al_atlas.ann.\n",
      "To load the instance again, please do `pacmap.load(/mnt/e/nanopore_processed/pacmap/uf_hembank_1852_pacmap_5d_model_al_atlas)`.\n"
     ]
    }
   ],
   "source": [
    "import pacmap\n",
    "print('PaCMAP version:', pacmap.__version__)\n",
    "\n",
    "components_list = [2, 5]\n",
    "for components in components_list:\n",
    "    \n",
    "    reducer = pacmap.PaCMAP(n_components=components, \n",
    "                            n_neighbors=10, \n",
    "                            MN_ratio=0.4, \n",
    "                            FP_ratio=16.0, \n",
    "                            lr=0.1, \n",
    "                            num_iters=5000,\n",
    "                            random_state=42,\n",
    "                            save_tree=True)\n",
    "\n",
    "    # Project the high dimensional dataset into a low-dimensional embedding\n",
    "    embedding_training = reducer.fit_transform(df_discovery.to_numpy(dtype='float16'))\n",
    "\n",
    "    # Save reducer\n",
    "    pacmap.save(reducer, nanopore_path + f'{sample_name}_pacmap_{components}d_model_al_atlas')\n",
    "\n",
    "    # Create column names\n",
    "    cols = ['PaCMAP '+ str(i+1) + f' of {components}' for i in range(components)]\n",
    "\n",
    "    # Turn embedding into dataframe\n",
    "    df_embedding = pd.DataFrame(embedding_training, columns=cols, index=df_discovery.index).to_pickle(\n",
    "        nanopore_path+f'{sample_name}_pacmap_{components}d_embedding.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply models to new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "def apply_pacmap_model_to_new_data(df, components):\n",
    "\n",
    "    # Load reducer\n",
    "    reducer = pacmap.load(nanopore_path + f'{sample_name}_pacmap_{components}d_model_al_atlas')\n",
    "\n",
    "    # Project the high dimensional dataset into existing embedding space and return the embedding.\n",
    "    embedding = reducer.transform(df.to_numpy(dtype='float16'))\n",
    "\n",
    "    # Create column names\n",
    "    cols = ['PaCMAP '+ str(i+1) + f' of {components}' for i in range(components)]\n",
    "\n",
    "    # Turn embedding into dataframe\n",
    "    df_embedding = pd.DataFrame(embedding, columns=cols, index=df.index)\n",
    "\n",
    "    return df_embedding\n",
    "\n",
    "# Apply pacmap model to discovery dataset\n",
    "train_2d = pd.read_pickle(nanopore_path+sample_name+'_pacmap_2d_embedding.pkl')\n",
    "train_5d = pd.read_pickle(nanopore_path+sample_name+'_pacmap_5d_embedding.pkl')\n",
    "\n",
    "# # Apply pacmap model to validation dataset\n",
    "test_2d = apply_pacmap_model_to_new_data(df_nanopore, components=2)\n",
    "test_5d = apply_pacmap_model_to_new_data(df_nanopore, components=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge results with clinical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Join 2d and 5d\n",
    "train = train_2d.join(train_5d)\n",
    "test = test_2d.join(test_5d)\n",
    "\n",
    "# Concatenate train and test\n",
    "train_test = pd.concat([train, test])\n",
    "\n",
    "# Read clinical data\n",
    "clinical_data = pd.read_excel(input_path+'clinical_data.xlsx', index_col=0)\n",
    "\n",
    "# Join train_test with clinical data\n",
    "df = train_test.join(clinical_data)\n",
    "\n",
    "train_test_5d = pd.concat([train_5d, test_5d])\n",
    "train_test_2d = pd.concat([train_2d, test_2d])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data for classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select samples Px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1465 samples removed. 1844 samples remaining.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Drop the samples with missing labels for the selected column\n",
    "df_px = df[~df['Vital Status'].isna()]\n",
    "\n",
    "df_px2 = df_px.copy()\n",
    "\n",
    "# # Exclude the `Blood Derived Normal`and `Bone Marrow Normal` from `Sample Type`\n",
    "# df_px2 = df_px[~df_px['Sample Type'].isin([\n",
    "#                                             'Relapse', 'Recurrent Blood Derived Cancer - Bone Marrow',\n",
    "#                                             'Recurrent Blood Derived Cancer - Peripheral Blood',\n",
    "#                                             'Blood Derived Normal', 'Bone Marrow Normal'\n",
    "# ])]\n",
    "\n",
    "# print the number of samples dropped and the amount remaining\n",
    "print(df.shape[0]-df_px2.shape[0], 'samples removed.'\\\n",
    ", df_px2.shape[0], 'samples remaining.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select samples Dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "864 samples removed. 2445 samples remaining.\n"
     ]
    }
   ],
   "source": [
    "# drop the samples with missing labels for the ELN AML 2022 Diagnosis\n",
    "df_dx = df[~df['WHO 2022 Diagnosis'].isna()]\n",
    "\n",
    "# exclude the classes with fewer than 10 samples\n",
    "df_dx2 = df_dx[~df_dx['WHO 2022 Diagnosis'].isin([\n",
    "                                       'MPAL with t(v;11q23.3)/KMT2A-r',\n",
    "                                       'B-ALL with hypodiploidy',\n",
    "                                       'AML with t(16;21); FUS::ERG',\n",
    "                                       'AML with t(9;22); BCR::ABL1'\n",
    "                                       ])]\n",
    "\n",
    "# print the number of samples dropped and the amount remaining\n",
    "print(df.shape[0]-df_dx2.shape[0], 'samples removed.'\\\n",
    ", df_dx2.shape[0], 'samples remaining.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (2445, 5) X_test shape: (0, 5)\n",
      "X_train shape: (1844, 5) X_test shape: (0, 5)\n"
     ]
    }
   ],
   "source": [
    "def custom_train_test_split(df, feature_columns, target_column, split_column):\n",
    "\n",
    "    X = df[feature_columns].to_numpy(dtype='float16')\n",
    "    y = df[target_column].to_numpy()\n",
    "\n",
    "    train_mask = df[split_column] == 'Train Sample'\n",
    "    test_mask = df[split_column] == 'Test Sample'\n",
    "\n",
    "    X_train, X_test = X[train_mask], X[test_mask]\n",
    "    y_train, y_test = y[train_mask], y[test_mask]\n",
    "\n",
    "    print('X_train shape:', X_train.shape, 'X_test shape:', X_test.shape)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# Execution\n",
    "X_train_dx, X_test_dx, y_train_dx, y_test_dx = custom_train_test_split(df_dx2, test_5d.columns,'WHO 2022 Diagnosis', 'Train-Test')\n",
    "X_train_px, X_test_px, y_train_px, y_test_px = custom_train_test_split(df_px2, test_5d.columns,'Vital Status', 'Train-Test')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'class_weight': 'balanced', 'reg_alpha': 1, 'reg_lambda': 1}\n",
      "Best parameters: {'class_weight': 'balanced', 'reg_alpha': 1, 'reg_lambda': 1}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from lightgbm import LGBMClassifier\n",
    "import joblib\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "def benchmark_classifier(X_train, y_train):\n",
    "\n",
    "    param_grid = {\n",
    "    # 'num_leaves': [ 5, 6, 7, 8, 9, 10], # number of leaves in full tree\n",
    "    # 'max_depth': [3,4,5,6,7,8,9,10],  # maximum depth of a tree\n",
    "    # 'learning_rate': [0.01],  # learning rate\n",
    "    # 'n_estimators': [50, 100, 500],  # number of trees (or rounds)\n",
    "    'reg_alpha': [1],  # L1 regularization\n",
    "    'reg_lambda': [1],  # L2 regularization\n",
    "    'class_weight': ['balanced'],  # weights associated with classes\n",
    "    }\n",
    "\n",
    "    # Initialize the LGBM Classifier with regularization\n",
    "    lgbm = LGBMClassifier(random_state=42, n_jobs=-1) \n",
    "                          \n",
    "    # Perform grid search with stratified cross-validation\n",
    "    grid_search = GridSearchCV(lgbm, param_grid, cv=10, n_jobs=-1,\n",
    "                               scoring='roc_auc_ovr_weighted')\n",
    "\n",
    "    # Fit the grid search to the data\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "\n",
    "    # Get the best model\n",
    "    clf = grid_search.best_estimator_\n",
    "\n",
    "    return clf\n",
    "\n",
    "# Benchmark, train\n",
    "lgbm_dx_model = benchmark_classifier(X_train_dx, y_train_dx)\n",
    "lgbm_px_model = benchmark_classifier(X_train_px, y_train_px)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply supervised models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AML Epigenomic Risk</th>\n",
       "      <th>AML Epigenomic Risk P(High Risk)</th>\n",
       "      <th>AL Epigenomic Phenotype</th>\n",
       "      <th>P(AML with NUP98-fusion)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>uf_hembank_1852</th>\n",
       "      <td>High</td>\n",
       "      <td>0.786</td>\n",
       "      <td>AML with NUP98-fusion</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                AML Epigenomic Risk  AML Epigenomic Risk P(High Risk)  \\\n",
       "uf_hembank_1852                High                             0.786   \n",
       "\n",
       "                AL Epigenomic Phenotype  P(AML with NUP98-fusion)  \n",
       "uf_hembank_1852   AML with NUP98-fusion                      0.83  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def save_predictions(df, classifier, model_name):\n",
    "\n",
    "    # ignore sklearn warnings\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "\n",
    "    # Select necessary columns\n",
    "    df_features = df.copy()\n",
    "\n",
    "    # Predict using the selected columns\n",
    "    predictions = classifier.predict(df_features)\n",
    "\n",
    "    # Predict probabilities using the selected columns\n",
    "    probabilities = classifier.predict_proba(df_features)\n",
    "\n",
    "    # Convert predictions to a Series with the same index as df_features\n",
    "    predictions_series = pd.Series(predictions, index=df_features.index, name=model_name)\n",
    "\n",
    "    # Convert probabilities to a DataFrame with the same index as df_features and the same columns as the classes\n",
    "    probabilities_df = pd.DataFrame(probabilities, index=df_features.index, columns=classifier.classes_).round(3)\n",
    "\n",
    "    # Add \" - predict_proba\" to the column names\n",
    "    probabilities_df.columns ='P(' + probabilities_df.columns + ')'\n",
    "\n",
    "    # Transform classes of the predictions into integers based on unique values in the classes\n",
    "    probabilities_df[model_name + '_int'] = predictions_series.map({c: i for i, c in enumerate(classifier.classes_)})\n",
    "\n",
    "    # Join predictions with the original DataFrame (already indexed)\n",
    "    df_joined = predictions_series.to_frame().join(probabilities_df)\n",
    "\n",
    "    return df_joined\n",
    "\n",
    "# Execution\n",
    "df_pred_px = save_predictions(df=train_test_5d, classifier=lgbm_px_model, model_name='AML Epigenomic Risk')\n",
    "df_pred_dx = save_predictions(df=train_test_5d, classifier=lgbm_dx_model, model_name='AL Epigenomic Phenotype')\n",
    "\n",
    "# Map the classes to more desirable labels (low and high risk)\n",
    "df_pred_px['AML Epigenomic Risk'] = df_pred_px['AML Epigenomic Risk'].map({'Alive': 'Low', 'Dead': 'High'})\n",
    "df_pred_px = df_pred_px.rename(columns={'P(Alive)': 'AML Epigenomic Risk P(Low Risk)', 'P(Dead)': 'AML Epigenomic Risk P(High Risk)'})\n",
    "\n",
    "# Join predictions with clinical data\n",
    "df_combined = train_test_2d.join(train_test_5d).join(df_pred_px).join(df_pred_dx)\n",
    "\n",
    "\n",
    "df_combined.iloc[-1:,:][['AML Epigenomic Risk', 'AML Epigenomic Risk P(High Risk)', 'AL Epigenomic Phenotype', f'P({df_combined.iloc[-1:,:][\"AL Epigenomic Phenotype\"].item()})']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "        .bk-notebook-logo {\n",
       "            display: block;\n",
       "            width: 20px;\n",
       "            height: 20px;\n",
       "            background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAABx0RVh0U29mdHdhcmUAQWRvYmUgRmlyZXdvcmtzIENTNui8sowAAAOkSURBVDiNjZRtaJVlGMd/1/08zzln5zjP1LWcU9N0NkN8m2CYjpgQYQXqSs0I84OLIC0hkEKoPtiH3gmKoiJDU7QpLgoLjLIQCpEsNJ1vqUOdO7ppbuec5+V+rj4ctwzd8IIbbi6u+8f1539dt3A78eXC7QizUF7gyV1fD1Yqg4JWz84yffhm0qkFqBogB9rM8tZdtwVsPUhWhGcFJngGeWrPzHm5oaMmkfEg1usvLFyc8jLRqDOMru7AyC8saQr7GG7f5fvDeH7Ej8CM66nIF+8yngt6HWaKh7k49Soy9nXurCi1o3qUbS3zWfrYeQDTB/Qj6kX6Ybhw4B+bOYoLKCC9H3Nu/leUTZ1JdRWkkn2ldcCamzrcf47KKXdAJllSlxAOkRgyHsGC/zRday5Qld9DyoM4/q/rUoy/CXh3jzOu3bHUVZeU+DEn8FInkPBFlu3+nW3Nw0mk6vCDiWg8CeJaxEwuHS3+z5RgY+YBR6V1Z1nxSOfoaPa4LASWxxdNp+VWTk7+4vzaou8v8PN+xo+KY2xsw6une2frhw05CTYOmQvsEhjhWjn0bmXPjpE1+kplmmkP3suftwTubK9Vq22qKmrBhpY4jvd5afdRA3wGjFAgcnTK2s4hY0/GPNIb0nErGMCRxWOOX64Z8RAC4oCXdklmEvcL8o0BfkNK4lUg9HTl+oPlQxdNo3Mg4Nv175e/1LDGzZen30MEjRUtmXSfiTVu1kK8W4txyV6BMKlbgk3lMwYCiusNy9fVfvvwMxv8Ynl6vxoByANLTWplvuj/nF9m2+PDtt1eiHPBr1oIfhCChQMBw6Aw0UulqTKZdfVvfG7VcfIqLG9bcldL/+pdWTLxLUy8Qq38heUIjh4XlzZxzQm19lLFlr8vdQ97rjZVOLf8nclzckbcD4wxXMidpX30sFd37Fv/GtwwhzhxGVAprjbg0gCAEeIgwCZyTV2Z1REEW8O4py0wsjeloKoMr6iCY6dP92H6Vw/oTyICIthibxjm/DfN9lVz8IqtqKYLUXfoKVMVQVVJOElGjrnnUt9T9wbgp8AyYKaGlqingHZU/uG2NTZSVqwHQTWkx9hxjkpWDaCg6Ckj5qebgBVbT3V3NNXMSiWSDdGV3hrtzla7J+duwPOToIg42ChPQOQjspnSlp1V+Gjdged7+8UN5CRAV7a5EdFNwCjEaBR27b3W890TE7g24NAP/mMDXRWrGoFPQI9ls/MWO2dWFAar/xcOIImbbpA3zgAAAABJRU5ErkJggg==);\n",
       "        }\n",
       "    </style>\n",
       "    <div>\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-notebook-logo\"></a>\n",
       "        <span id=\"ac80161a-95bf-456a-ac42-41bb7e822433\">Loading BokehJS ...</span>\n",
       "    </div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\nconst JS_MIME_TYPE = 'application/javascript';\n  const HTML_MIME_TYPE = 'text/html';\n  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n  const CLASS_NAME = 'output_bokeh rendered_html';\n\n  /**\n   * Render data to the DOM node\n   */\n  function render(props, node) {\n    const script = document.createElement(\"script\");\n    node.appendChild(script);\n  }\n\n  /**\n   * Handle when an output is cleared or removed\n   */\n  function handleClearOutput(event, handle) {\n    const cell = handle.cell;\n\n    const id = cell.output_area._bokeh_element_id;\n    const server_id = cell.output_area._bokeh_server_id;\n    // Clean up Bokeh references\n    if (id != null && id in Bokeh.index) {\n      Bokeh.index[id].model.document.clear();\n      delete Bokeh.index[id];\n    }\n\n    if (server_id !== undefined) {\n      // Clean up Bokeh references\n      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n      cell.notebook.kernel.execute(cmd_clean, {\n        iopub: {\n          output: function(msg) {\n            const id = msg.content.text.trim();\n            if (id in Bokeh.index) {\n              Bokeh.index[id].model.document.clear();\n              delete Bokeh.index[id];\n            }\n          }\n        }\n      });\n      // Destroy server and session\n      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n      cell.notebook.kernel.execute(cmd_destroy);\n    }\n  }\n\n  /**\n   * Handle when a new output is added\n   */\n  function handleAddOutput(event, handle) {\n    const output_area = handle.output_area;\n    const output = handle.output;\n\n    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n      return\n    }\n\n    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n\n    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n      // store reference to embed id on output_area\n      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n    }\n    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n      const bk_div = document.createElement(\"div\");\n      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n      const script_attrs = bk_div.children[0].attributes;\n      for (let i = 0; i < script_attrs.length; i++) {\n        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n      }\n      // store reference to server id on output_area\n      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n    }\n  }\n\n  function register_renderer(events, OutputArea) {\n\n    function append_mime(data, metadata, element) {\n      // create a DOM node to render to\n      const toinsert = this.create_output_subarea(\n        metadata,\n        CLASS_NAME,\n        EXEC_MIME_TYPE\n      );\n      this.keyboard_manager.register_events(toinsert);\n      // Render to node\n      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n      render(props, toinsert[toinsert.length - 1]);\n      element.append(toinsert);\n      return toinsert\n    }\n\n    /* Handle when an output is cleared or removed */\n    events.on('clear_output.CodeCell', handleClearOutput);\n    events.on('delete.Cell', handleClearOutput);\n\n    /* Handle when a new output is added */\n    events.on('output_added.OutputArea', handleAddOutput);\n\n    /**\n     * Register the mime type and append_mime function with output_area\n     */\n    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n      /* Is output safe? */\n      safe: true,\n      /* Index of renderer in `output_area.display_order` */\n      index: 0\n    });\n  }\n\n  // register the mime type if in Jupyter Notebook environment and previously unregistered\n  if (root.Jupyter !== undefined) {\n    const events = require('base/js/events');\n    const OutputArea = require('notebook/js/outputarea').OutputArea;\n\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  }\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    const el = document.getElementById(\"ac80161a-95bf-456a-ac42-41bb7e822433\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.1.1.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n          for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\nif (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"ac80161a-95bf-456a-ac42-41bb7e822433\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));",
      "application/vnd.bokehjs_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"e38b1eb0-5412-4e1a-808b-fc266e50208d\" data-root-id=\"p14262\" style=\"display: contents;\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "(function(root) {\n  function embed_document(root) {\n  const docs_json = {\"df9d7db4-1402-450a-be08-a6df3f517e1c\":{\"version\":\"3.1.1\",\"title\":\"Bokeh Application\",\"defs\":[],\"roots\":[{\"type\":\"object\",\"name\":\"Figure\",\"id\":\"p14262\",\"attributes\":{\"height\":200,\"x_range\":{\"type\":\"object\",\"name\":\"DataRange1d\",\"id\":\"p14264\",\"attributes\":{\"start\":0,\"end\":1}},\"y_range\":{\"type\":\"object\",\"name\":\"FactorRange\",\"id\":\"p14261\",\"attributes\":{\"factors\":[\"P(AML with t(1;22); RBM15::MKL1)\",\"P(AML with t(v;11q23); KMT2A-r)\",\"P(AML with CBFA2T3::GLIS2)\",\"P(MDS-related; secondary myeloid)\",\"P(AML with NUP98-fusion)\"],\"range_padding\":0.1}},\"x_scale\":{\"type\":\"object\",\"name\":\"LinearScale\",\"id\":\"p14275\"},\"y_scale\":{\"type\":\"object\",\"name\":\"CategoricalScale\",\"id\":\"p14277\"},\"title\":{\"type\":\"object\",\"name\":\"Title\",\"id\":\"p14265\",\"attributes\":{\"text\":\"Predicted Probabilities of WHO 2022 Diagnosis\"}},\"renderers\":[{\"type\":\"object\",\"name\":\"GlyphRenderer\",\"id\":\"p14314\",\"attributes\":{\"data_source\":{\"type\":\"object\",\"name\":\"ColumnDataSource\",\"id\":\"p14258\",\"attributes\":{\"selected\":{\"type\":\"object\",\"name\":\"Selection\",\"id\":\"p14259\",\"attributes\":{\"indices\":[],\"line_indices\":[]}},\"selection_policy\":{\"type\":\"object\",\"name\":\"UnionRenderers\",\"id\":\"p14260\"},\"data\":{\"type\":\"map\",\"entries\":[[\"diagnoses\",[\"P(AML with t(1;22); RBM15::MKL1)\",\"P(AML with t(v;11q23); KMT2A-r)\",\"P(AML with CBFA2T3::GLIS2)\",\"P(MDS-related; secondary myeloid)\",\"P(AML with NUP98-fusion)\"]],[\"probabilities\",[0.009,0.026,0.029,0.055,0.83]]]}}},\"view\":{\"type\":\"object\",\"name\":\"CDSView\",\"id\":\"p14315\",\"attributes\":{\"filter\":{\"type\":\"object\",\"name\":\"AllIndices\",\"id\":\"p14316\"}}},\"glyph\":{\"type\":\"object\",\"name\":\"HBar\",\"id\":\"p14311\",\"attributes\":{\"y\":{\"type\":\"field\",\"field\":\"diagnoses\"},\"right\":{\"type\":\"field\",\"field\":\"probabilities\"},\"line_color\":{\"type\":\"value\",\"value\":\"#1f77b4\"},\"fill_color\":{\"type\":\"field\",\"field\":\"diagnoses\",\"transform\":{\"type\":\"object\",\"name\":\"CategoricalColorMapper\",\"id\":\"p14307\",\"attributes\":{\"palette\":[\"#440154\",\"#440255\",\"#440357\",\"#450558\",\"#45065A\",\"#45085B\",\"#46095C\",\"#460B5E\",\"#460C5F\",\"#460E61\",\"#470F62\",\"#471163\",\"#471265\",\"#471466\",\"#471567\",\"#471669\",\"#47186A\",\"#48196B\",\"#481A6C\",\"#481C6E\",\"#481D6F\",\"#481E70\",\"#482071\",\"#482172\",\"#482273\",\"#482374\",\"#472575\",\"#472676\",\"#472777\",\"#472878\",\"#472A79\",\"#472B7A\",\"#472C7B\",\"#462D7C\",\"#462F7C\",\"#46307D\",\"#46317E\",\"#45327F\",\"#45347F\",\"#453580\",\"#453681\",\"#443781\",\"#443982\",\"#433A83\",\"#433B83\",\"#433C84\",\"#423D84\",\"#423E85\",\"#424085\",\"#414186\",\"#414286\",\"#404387\",\"#404487\",\"#3F4587\",\"#3F4788\",\"#3E4888\",\"#3E4989\",\"#3D4A89\",\"#3D4B89\",\"#3D4C89\",\"#3C4D8A\",\"#3C4E8A\",\"#3B508A\",\"#3B518A\",\"#3A528B\",\"#3A538B\",\"#39548B\",\"#39558B\",\"#38568B\",\"#38578C\",\"#37588C\",\"#37598C\",\"#365A8C\",\"#365B8C\",\"#355C8C\",\"#355D8C\",\"#345E8D\",\"#345F8D\",\"#33608D\",\"#33618D\",\"#32628D\",\"#32638D\",\"#31648D\",\"#31658D\",\"#31668D\",\"#30678D\",\"#30688D\",\"#2F698D\",\"#2F6A8D\",\"#2E6B8E\",\"#2E6C8E\",\"#2E6D8E\",\"#2D6E8E\",\"#2D6F8E\",\"#2C708E\",\"#2C718E\",\"#2C728E\",\"#2B738E\",\"#2B748E\",\"#2A758E\",\"#2A768E\",\"#2A778E\",\"#29788E\",\"#29798E\",\"#287A8E\",\"#287A8E\",\"#287B8E\",\"#277C8E\",\"#277D8E\",\"#277E8E\",\"#267F8E\",\"#26808E\",\"#26818E\",\"#25828E\",\"#25838D\",\"#24848D\",\"#24858D\",\"#24868D\",\"#23878D\",\"#23888D\",\"#23898D\",\"#22898D\",\"#228A8D\",\"#228B8D\",\"#218C8D\",\"#218D8C\",\"#218E8C\",\"#208F8C\",\"#20908C\",\"#20918C\",\"#1F928C\",\"#1F938B\",\"#1F948B\",\"#1F958B\",\"#1F968B\",\"#1E978A\",\"#1E988A\",\"#1E998A\",\"#1E998A\",\"#1E9A89\",\"#1E9B89\",\"#1E9C89\",\"#1E9D88\",\"#1E9E88\",\"#1E9F88\",\"#1EA087\",\"#1FA187\",\"#1FA286\",\"#1FA386\",\"#20A485\",\"#20A585\",\"#21A685\",\"#21A784\",\"#22A784\",\"#23A883\",\"#23A982\",\"#24AA82\",\"#25AB81\",\"#26AC81\",\"#27AD80\",\"#28AE7F\",\"#29AF7F\",\"#2AB07E\",\"#2BB17D\",\"#2CB17D\",\"#2EB27C\",\"#2FB37B\",\"#30B47A\",\"#32B57A\",\"#33B679\",\"#35B778\",\"#36B877\",\"#38B976\",\"#39B976\",\"#3BBA75\",\"#3DBB74\",\"#3EBC73\",\"#40BD72\",\"#42BE71\",\"#44BE70\",\"#45BF6F\",\"#47C06E\",\"#49C16D\",\"#4BC26C\",\"#4DC26B\",\"#4FC369\",\"#51C468\",\"#53C567\",\"#55C666\",\"#57C665\",\"#59C764\",\"#5BC862\",\"#5EC961\",\"#60C960\",\"#62CA5F\",\"#64CB5D\",\"#67CC5C\",\"#69CC5B\",\"#6BCD59\",\"#6DCE58\",\"#70CE56\",\"#72CF55\",\"#74D054\",\"#77D052\",\"#79D151\",\"#7CD24F\",\"#7ED24E\",\"#81D34C\",\"#83D34B\",\"#86D449\",\"#88D547\",\"#8BD546\",\"#8DD644\",\"#90D643\",\"#92D741\",\"#95D73F\",\"#97D83E\",\"#9AD83C\",\"#9DD93A\",\"#9FD938\",\"#A2DA37\",\"#A5DA35\",\"#A7DB33\",\"#AADB32\",\"#ADDC30\",\"#AFDC2E\",\"#B2DD2C\",\"#B5DD2B\",\"#B7DD29\",\"#BADE27\",\"#BDDE26\",\"#BFDF24\",\"#C2DF22\",\"#C5DF21\",\"#C7E01F\",\"#CAE01E\",\"#CDE01D\",\"#CFE11C\",\"#D2E11B\",\"#D4E11A\",\"#D7E219\",\"#DAE218\",\"#DCE218\",\"#DFE318\",\"#E1E318\",\"#E4E318\",\"#E7E419\",\"#E9E419\",\"#ECE41A\",\"#EEE51B\",\"#F1E51C\",\"#F3E51E\",\"#F6E61F\",\"#F8E621\",\"#FAE622\",\"#FDE724\"],\"factors\":[\"P(AML with t(1;22); RBM15::MKL1)\",\"P(AML with t(v;11q23); KMT2A-r)\",\"P(AML with CBFA2T3::GLIS2)\",\"P(MDS-related; secondary myeloid)\",\"P(AML with NUP98-fusion)\"]}}}}},\"nonselection_glyph\":{\"type\":\"object\",\"name\":\"HBar\",\"id\":\"p14312\",\"attributes\":{\"y\":{\"type\":\"field\",\"field\":\"diagnoses\"},\"right\":{\"type\":\"field\",\"field\":\"probabilities\"},\"line_color\":{\"type\":\"value\",\"value\":\"#1f77b4\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.1},\"fill_color\":{\"type\":\"field\",\"field\":\"diagnoses\",\"transform\":{\"id\":\"p14307\"}},\"fill_alpha\":{\"type\":\"value\",\"value\":0.1},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.1}}},\"muted_glyph\":{\"type\":\"object\",\"name\":\"HBar\",\"id\":\"p14313\",\"attributes\":{\"y\":{\"type\":\"field\",\"field\":\"diagnoses\"},\"right\":{\"type\":\"field\",\"field\":\"probabilities\"},\"line_color\":{\"type\":\"value\",\"value\":\"#1f77b4\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.2},\"fill_color\":{\"type\":\"field\",\"field\":\"diagnoses\",\"transform\":{\"id\":\"p14307\"}},\"fill_alpha\":{\"type\":\"value\",\"value\":0.2},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.2}}}}}],\"toolbar\":{\"type\":\"object\",\"name\":\"Toolbar\",\"id\":\"p14271\",\"attributes\":{\"logo\":null,\"tools\":[{\"type\":\"object\",\"name\":\"PanTool\",\"id\":\"p14292\"},{\"type\":\"object\",\"name\":\"WheelZoomTool\",\"id\":\"p14293\"},{\"type\":\"object\",\"name\":\"BoxZoomTool\",\"id\":\"p14294\",\"attributes\":{\"overlay\":{\"type\":\"object\",\"name\":\"BoxAnnotation\",\"id\":\"p14295\",\"attributes\":{\"syncable\":false,\"level\":\"overlay\",\"visible\":false,\"left_units\":\"canvas\",\"right_units\":\"canvas\",\"bottom_units\":\"canvas\",\"top_units\":\"canvas\",\"line_color\":\"black\",\"line_alpha\":1.0,\"line_width\":2,\"line_dash\":[4,4],\"fill_color\":\"lightgrey\",\"fill_alpha\":0.5}}}},{\"type\":\"object\",\"name\":\"SaveTool\",\"id\":\"p14296\"},{\"type\":\"object\",\"name\":\"ResetTool\",\"id\":\"p14297\"},{\"type\":\"object\",\"name\":\"HelpTool\",\"id\":\"p14298\"},{\"type\":\"object\",\"name\":\"HoverTool\",\"id\":\"p14317\",\"attributes\":{\"renderers\":\"auto\",\"tooltips\":[[\"Diagnosis\",\"@diagnoses\"],[\"Probability\",\"@probabilities{0.000}\"]]}}]}},\"left\":[{\"type\":\"object\",\"name\":\"CategoricalAxis\",\"id\":\"p14286\",\"attributes\":{\"ticker\":{\"type\":\"object\",\"name\":\"CategoricalTicker\",\"id\":\"p14287\"},\"formatter\":{\"type\":\"object\",\"name\":\"CategoricalTickFormatter\",\"id\":\"p14289\"},\"axis_label\":\"WHO 2022 Diagnosis\",\"major_label_orientation\":0,\"major_label_policy\":{\"type\":\"object\",\"name\":\"AllLabels\",\"id\":\"p14288\"}}}],\"below\":[{\"type\":\"object\",\"name\":\"LinearAxis\",\"id\":\"p14279\",\"attributes\":{\"ticker\":{\"type\":\"object\",\"name\":\"BasicTicker\",\"id\":\"p14280\",\"attributes\":{\"mantissas\":[1,2,5]}},\"formatter\":{\"type\":\"object\",\"name\":\"BasicTickFormatter\",\"id\":\"p14282\"},\"axis_label\":\"Predicted Probability\",\"major_label_orientation\":1,\"major_label_policy\":{\"type\":\"object\",\"name\":\"AllLabels\",\"id\":\"p14281\"}}}],\"center\":[{\"type\":\"object\",\"name\":\"Grid\",\"id\":\"p14285\",\"attributes\":{\"axis\":{\"id\":\"p14279\"},\"grid_line_color\":null}},{\"type\":\"object\",\"name\":\"Grid\",\"id\":\"p14291\",\"attributes\":{\"dimension\":1,\"axis\":{\"id\":\"p14286\"}}}]}}],\"callbacks\":{\"type\":\"map\"}}};\n  const render_items = [{\"docid\":\"df9d7db4-1402-450a-be08-a6df3f517e1c\",\"roots\":{\"p14262\":\"e38b1eb0-5412-4e1a-808b-fc266e50208d\"},\"root_ids\":[\"p14262\"]}];\n  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n  }\n  if (root.Bokeh !== undefined) {\n    embed_document(root);\n  } else {\n    let attempts = 0;\n    const timer = setInterval(function(root) {\n      if (root.Bokeh !== undefined) {\n        clearInterval(timer);\n        embed_document(root);\n      } else {\n        attempts++;\n        if (attempts > 100) {\n          clearInterval(timer);\n          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n        }\n      }\n    }, 10, root)\n  }\n})(window);",
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "p14262"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from bokeh.io import show, output_notebook\n",
    "from bokeh.models import ColumnDataSource, FactorRange, HoverTool\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.transform import factor_cmap\n",
    "\n",
    "# Prepare the data\n",
    "data = df_pred_dx.iloc[-1, 1:-1]\n",
    "\n",
    "# Sort columns by values\n",
    "data = data.sort_values().iloc[-5:]\n",
    "\n",
    "source = ColumnDataSource(data=dict(diagnoses=data.index.tolist(),\n",
    "                                    probabilities=data.values.tolist()))\n",
    "\n",
    "# Set the output to notebook\n",
    "output_notebook()\n",
    "\n",
    "# Create the figure\n",
    "p = figure(y_range=FactorRange(*data.index.tolist()), height=200, \n",
    "           title=\"Predicted Probabilities of WHO 2022 Diagnosis\",)\n",
    "\n",
    "# Add a horizontal bar chart\n",
    "p.hbar(y='diagnoses', right='probabilities', source=source, \n",
    "       fill_color=factor_cmap('diagnoses', palette=\"Viridis256\",\n",
    "                              factors=data.index.tolist()))\n",
    "\n",
    "# Set the axis labels\n",
    "p.xaxis.axis_label = \"Predicted Probability\"\n",
    "p.yaxis.axis_label = \"WHO 2022 Diagnosis\"\n",
    "\n",
    "# Add hover tool\n",
    "hover = HoverTool()\n",
    "hover.tooltips = [(\"Diagnosis\", \"@diagnoses\"), (\"Probability\", \"@probabilities{0.000}\")]\n",
    "p.add_tools(hover)\n",
    "\n",
    "# hide logo\n",
    "p.toolbar.logo = None\n",
    "\n",
    "# # Set other options\n",
    "p.x_range.start = 0\n",
    "p.x_range.end = 1\n",
    "p.y_range.range_padding = 0.1\n",
    "p.yaxis.major_label_orientation = 0  # Adjusted to make labels horizontal\n",
    "p.xaxis.major_label_orientation = 1\n",
    "p.xgrid.grid_line_color = None\n",
    "\n",
    "# Display the plot\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EWASCox-Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuous score cut at the value of 0.4934\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>name</th>\n",
       "      <th>EWASCox_OS_48CpGs</th>\n",
       "      <th>EWASCox_OS_48CpGs Categorical</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>uf_hembank_1852</th>\n",
       "      <td>-0.722272</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "name             EWASCox_OS_48CpGs EWASCox_OS_48CpGs Categorical\n",
       "uf_hembank_1852          -0.722272                           Low"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from source.cox_lasso import *\n",
    "\n",
    "raw_coefs = pd.read_csv(output_path + 'multivariate_cox_lasso/ewas_cog_os_raw_coefs_newrisk.csv', index_col=0)\n",
    "\n",
    "mean_coefs = set_cutoff(coefs=raw_coefs,threshold=0.99)\n",
    "\n",
    "df_validation = df_nanopore[mean_coefs.index]\n",
    "\n",
    "df_validation_transformed = df_validation.replace(1, 0.999).replace(0, 0.001)\n",
    "\n",
    "def beta2m(val):\n",
    "    '''Transfrom beta-values into m-values'''\n",
    "    return math.log2(val/(1-val))\n",
    "\n",
    "x_test_m = df_validation_transformed.apply(np.vectorize(beta2m))\n",
    "\n",
    "def standardize_data(df, reference_df):\n",
    "    \"\"\"Standardize data using mean and standard deviation of reference dataset\"\"\"\n",
    "\n",
    "    # Keep only columns that are in both datasets\n",
    "    reference_df = reference_df.loc[:, df.columns]\n",
    "\n",
    "    # Standardize data\n",
    "    df_z = (df - reference_df.mean()) / reference_df.std()\n",
    "\n",
    "    return df_z\n",
    "\n",
    "# Read top CpGs selected from previous code file (univariate cox-ph EWAS)\n",
    "ewas_top_cpgs = pd.read_csv(output_path+'ewas_dmr/ewas_top_cpgs_os.csv', index_col=0)\n",
    "\n",
    "# Standardize data\n",
    "x_test_m_z = standardize_data(df= x_test_m, reference_df= ewas_top_cpgs)\n",
    "\n",
    "score_name = 'EWASCox_OS_48CpGs'\n",
    "\n",
    "df_test, threshold = generate_coxph_score(coef_mean=mean_coefs,\n",
    "                                        x=x_test_m_z,\n",
    "                                        df=df_validation_transformed,\n",
    "                                        score_name=score_name,\n",
    "                                        train_test=0.4934,\n",
    "                                        rpart_outcome='os.time')\n",
    "\n",
    "df_validation_transformed[['EWASCox_OS_48CpGs','EWASCox_OS_48CpGs Categorical']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data for uf_hembank_1852 saved as /mnt/e/MethylScore_v2/Processed_Data/uf_hembank_1852_processed.pkl\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df_nanopore = df_combined.join(df_validation_transformed[['EWASCox_OS_48CpGs','EWASCox_OS_48CpGs Categorical']])\n",
    "except:\n",
    "    df_nanopore = df_combined.copy()\n",
    "\n",
    "# Merge with clinical data\n",
    "df_nanopore = df_nanopore.join(clinical_data)\n",
    "\n",
    "# Update the 'Train-Test' column of the last row\n",
    "df_nanopore.iat[-1, df_nanopore.columns.get_loc('Train-Test')] = 'Long-read ONTseq'\n",
    "\n",
    "# Update the 'Clinical Trial' column of the last row\n",
    "df_nanopore.iat[-1, df_nanopore.columns.get_loc('Clinical Trial')] = 'UF HemBank'\n",
    "\n",
    "# Update the 'Patient_ID' column of the last row\n",
    "df_nanopore.iat[-1, df_nanopore.columns.get_loc('Patient_ID')] = sample_name\n",
    "\n",
    "# Save\n",
    "df_nanopore.to_pickle(output_path + sample_name + '_processed.pkl')\n",
    "\n",
    "# print save message\n",
    "print(f'Processed data for {sample_name} saved as {output_path + sample_name + \"_processed.pkl\"}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input",
     "remove-output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The watermark extension is already loaded. To reload it, use:\n",
      "  %reload_ext watermark\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Francisco_Marchi@Lamba_Lab_UF\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.8.18\n",
      "IPython version      : 8.12.2\n",
      "\n",
      "numpy   : 1.24.3\n",
      "pandas  : 2.0.2\n",
      "pacmap  : 0.7.0\n",
      "sklearn : 1.2.2\n",
      "lightgbm: 3.3.5\n",
      "\n",
      "Compiler    : GCC 11.4.0\n",
      "OS          : Linux\n",
      "Release     : 5.15.133.1-microsoft-standard-WSL2\n",
      "Machine     : x86_64\n",
      "Processor   : x86_64\n",
      "CPU cores   : 32\n",
      "Architecture: 64bit\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# watermark with all libraries used in this notebook\n",
    "%watermark -v -p numpy,pandas,pacmap,sklearn,lightgbm -a Francisco_Marchi@Lamba_Lab_UF -d -m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{note}\n",
    "Updating to python 3.10 caused substantial delays in lightgbm, so please use the following versions:\n",
    "`python`: 3.8.16\n",
    "`pacmap`: 0.7.0\n",
    "`lightgbm`: 3.3.5\n",
    "`scikit-learn`: 1.2.2\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
